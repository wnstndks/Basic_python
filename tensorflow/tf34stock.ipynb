{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNJv1TcOK1Q/yxrRE9r0XL8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# CNN+LSTM + Dense 모델을 작성해 주가 예측\n","삼성전자 증권표준코드 005930 를 이용해서 주가 예측"],"metadata":{"id":"9IVGwwfbVJtO"}},{"cell_type":"code","source":["!pip install finance-datareader"],"metadata":{"id":"yw4DfaMBWCtR"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bm9x-TknVEHI"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import FinanceDataReader as fdr\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","STOCK_CODE='005930'\n","stock=fdr.DataReader(STOCK_CODE)\n","\n","print(stock.head(3))\n","print(stock.tail(3))\n","print()\n","\n","# Date열을 이용해 연도별 주가 변동 시각화\n","# Date열을 연,월,일로 분리해 새로운 열을 추가\n","print(stock.index)\n","stock['year']=stock.index.year\n","stock['month']=stock.index.month\n","stock['day']=stock.index.day\n","print(stock.head(3))\n","print(stock.shape)\n","\n","plt.figure(figsize=(6,4))\n","sns.lineplot(y=stock['Close'],x=stock.year)\n","plt.xlabel('time')\n","plt.ylabel('price')\n","plt.show()"]},{"cell_type":"code","source":["time_step=[['2000','2005'],['2005','2010'],['2010','2015'],['2015','2023']]\n","fig,axes=plt.subplots(2,2)\n","fig.set_size_inches(10,6)\n","\n","for i in range(4):\n","    ax=axes[i//2,i%2]\n","    df=stock.loc[(stock.index>time_step[i][0])&(stock.index<time_step[i][1])]\n","    sns.lineplot(y=df['Close'],x=df.index,ax=ax)\n","    plt.xlabel('time')\n","    plt.ylabel('price')\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"yyna0-3VWD0A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 전처리: Open High Low Close Volumne\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scale_cols = ['Open','High','Low','Close','Volume']\n","df_scaled = scaler.fit_transform(stock[scale_cols])\n","df= pd.DataFrame(df_scaled,columns=scale_cols)\n","print(df.head(2))\n","print()\n","\n","# train_test split\n","from sklearn.model_selection import train_test_split\n","x_train,x_test, y_train,y_test = train_test_split(df.drop('Close',1),df['Close'],test_size=0.2,random_state=12,shuffle=False)\n","print(x_train.shape, x_test.shape, y_train.shape, y_test.shape) #(4800, 4) (1200, 4) (4800,) (1200,)\n","print()\n","print(x_train[:2])\n","print()\n","print(y_train[:2])\n","\n"],"metadata":{"id":"nFcgdTodYPRU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN+ - CONV1D를 사용해야 함\n","# Dataset을 활용해서 sequence dataset을 구성\n","import tensorflow as tf\n","\n","def window_dataset_func(series,window_size,batch_size,shuffle):\n","    series = tf.expand_dims(series,axis=-1)\n","    ds=tf.data.Dataset.from_tensor_slices(series) #예) (60000,28, 28) -> 28*28의 크기 6만개로 슬라이싱\n","    ds=ds.window(window_size+1, shift=1, drop_remainder=True) #Dataset.window(그룹화할 윈도우 크기, 이동수)- shift 값에 따라 그리고, remainder가 true냐 false임에 따라 슬라이싱해서 시계열 데이터를 표현할 수 잇음\n","    ds= ds.flat_map(lambda w:w.batch(window_size+1)) # map- 함수를 실행하는 함수\n","    if shuffle:\n","        ds=ds.shuffle(buffer_size=1000)\n","    ds=ds.map(lambda w:(w[:-1],w[-1]))\n","    return ds.batch(batch_size).prefetch(1) # prefetch(1)-dataset 1개(20단위 데이터)를 미리 준비해 둠. 훈련속도를 더 빠르게 처리\n","    #ds. batch(batch_size) - 큰데이터는 메모리에 한번에 올릴수 없으므로 batch_size만큼 나누어 학습을 시켜야 한다.\n","\n","\n","WINDOW_SIZE=20\n","BATCH_SIZE=32\n","train_data=window_dataset_func(y_train,WINDOW_SIZE,BATCH_SIZE,True) #train data는 shffuling하기 -꼭 안섞을 필요는 없음 y_train은 (4800,)짜리 label\n","test_data=window_dataset_func(y_test,WINDOW_SIZE,BATCH_SIZE,False) #그러나 test는 원래의 데이터를 그대로 유지해야 한다- 검증데이터이기 때문\n","print(train_data)\n","print(test_data)\n","\n","for data in train_data.take(1):\n","    print(data[0].shape) #(32, 20, 1) - batch_size,window_size,feature\n","    print(data[1].shape) #(32, 1) - batch_size,feature\n","    #이런식으로 끊어가면서 학습하는 것- DataSet이 이것을 도와주는 것임\n"],"metadata":{"id":"U5q6oJu9ZaRG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM,Conv1D\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.losses import Huber\n","from keras.optimizers import Adam #전통적인 방식에서는 최소제곱법을 사용, optimizers를 import\n","\n","model= Sequential([\n","    Conv1D(filters=32,kernel_size=5,padding='causal', activation='relu', input_shape=[WINDOW_SIZE,1]),  # 시간 순서를 위반하지 않는 시계열 데이터를 처리시 효과적\n","    LSTM(16,activation='tanh'),\n","    Dense(16,activation='relu'),\n","    Dense(1)\n","])\n","\n","\n","print(model.summary())\n","\n","loss=Huber()\n","optimizer=Adam(learning_rate=0.0005)\n","model.compile(loss=loss,optimizer=optimizer,metrics=['mse'])\n","\n","es=EarlyStopping(monitor='val_loss', patience=30)\n","\n","history=model.fit(train_data,epochs=100, batch_size=32, validation_data=(test_data),verbose=2,callbacks=[es])\n"],"metadata":{"id":"LfSKxFZOfGPJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred= model.predict(test_data)\n","print('예측값 : ', pred[:10].flatten())\n","print('실제값 : ', np.asarray(y_test)[:10])\n","\n","plt.figure(figsize=(8,5))\n","plt.plot(np.asarray(y_test)[20:], label='real')\n","plt.plot(pred,label='pred',c='blue')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"0i6FP325zrHq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"4TAk9VRp2SIJ"},"execution_count":null,"outputs":[]}]}