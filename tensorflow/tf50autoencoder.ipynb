{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPTtvanlDU6Y5kQrGKPCwxy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Auto Encoer란?\n","입력데이터를 압축시켜 압축시킨 데이터로 축소한 후 다시 확장하여 결과 데이터를 입력 데이터와 동일하도록 만드는 일종의 딥 뉴럴 네트워크 모델이다."],"metadata":{"id":"fWMkaYss7K4P"}},{"cell_type":"markdown","source":["## Dense만 사용해서 모델을 작성해보자\n","\n","MNIST dataset 사용"],"metadata":{"id":"ryNjNFKU7qbV"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.layers import Input, Dense\n","from keras.models import Model\n"],"metadata":{"id":"MW4U_ZJq7Kl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VSmeIsJf3U8g"},"outputs":[],"source":["def create_autoencoder(encoding_dim=32, image_shape=(784,)):\n","  # encoder\n","  input_img = Input(shape=image_shape)\n","#   encoded = Dense(encoding_dim, activation='relu')(input_img)\n","\n","  encoded = Dense(encoding_dim, activation='relu')(input_img)\n","  encoded = Dense(64, activation='relu')(encoded)\n","  encoded = Dense(32, activation='relu')(encoded)\n","\n","\n","  # decoder\n","  # decoded = Dense(image_shape[0], activation='sigmoid')(encoded)\n","  decoded=Dense(32,activation='relu')(encoded)\n","  decoded=Dense(64,activation='relu')(decoded)\n","  decoded = Dense(image_shape[0], activation='sigmoid')(decoded)\n","\n","  # autoencoder model\n","  autoencoder = Model(input_img, decoded)\n","  print(autoencoder.summary())\n","  encoder = Model(input_img, encoded)\n","\n","  # decoder model\n","#   encoded_input = Input(shape = (encoding_dim,))\n","#   decoder_layer = autoencoder.layers[-1]\n","#   decoder = Model(encoded_input, decoder_layer(encoded_input))\n","#   print(decoder.summary())\n","  encoded_input = Input(shape = (32,))\n","  decoder_layer = autoencoder.layers[4](encoded_input)\n","  decoder_layer = autoencoder.layers[5](decoder_layer)\n","  decoder_layer = autoencoder.layers[6](decoder_layer)\n","  decoder = Model(encoded_input, decoder_layer)\n","\n","  return autoencoder, encoder, decoder\n","\n","def prepare_data():\n","  (x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n","  x_train = x_train.astype('float32') / 255.\n","  x_test = x_test.astype('float32') / 255.\n","  x_train = x_train.reshape(len(x_train), np.prod(x_train.shape[1:]))\n","  x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n","  print(x_train.shape, ' ', x_test.shape)\n","  return x_train, x_test\n","\n","def display_Images(original, reconstructed, n=10):\n","  plt.figure(figsize=(20,4))\n","  for i in range(n):\n","    # original\n","    ax = plt.subplot(2, n, i +1)\n","    plt.imshow(original[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visibel(False)\n","\n","    # reconstructed\n","    ax = plt.subplot(2, n, i + 1 + n)\n","    plt.imshow(original[i].reshape(28, 28))\n","    plt.gray()\n","    ax.get_xaxis().set_visible(False)\n","    ax.get_yaxis().set_visibel(False)\n","\n","  plt.show()"]},{"cell_type":"code","source":["if __name__ =='__main__':\n","    # encoding_dim=32\n","    encoding_dim=128\n","    autoencoder,encoder,decoder=create_autoencoder(encoding_dim)\n","    autoencoder.compile(optimizer='adam',loss='binary_crossentropy') #loss가 binary인이유: 아까 sigmoid 사용했기 때문에\n","\n","    x_train,x_test=prepare_data()\n","\n","    autoencoder.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test,x_test),verbose=2) #label이 없기에 6만개 6만개를 넣어주어야 한다.\n","\n","    encoded_img=encoder.predict(x_test)\n","    decoded_img =decoder.predict(encoded_img)\n","\n","    display_images(x_test, decoded_img)\n"],"metadata":{"id":"cT_MNMDa9idV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2xf0l7h2IzWa"},"execution_count":null,"outputs":[]}]}