{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNm0+Y6juVPvgW3O03ovBlR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# DCGAN   - 비지도 학습\n","CNN을 GAN에 적용한 알고리즘\n","\n","MNIST dataset을 사용할 것\n","\n","input -> Generator(생성자) -> take -> Descriminator가 판별(원본과 구분할 수 없는 가짜 데이터가 생성될 때까지 반복)"],"metadata":{"id":"RfYm30kuog8a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ToDfk1tyoS_s"},"outputs":[],"source":["from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Activation, Conv2D, UpSampling2D, LeakyReLU\n","from keras.models import Sequential, Model\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import os"]},{"cell_type":"code","source":["# Generator가 만드는 이미지 저장 폴더\n","if not os.path.exists('./gan_imgs'):\n","  os.makedirs('./gan_imgs')\n","\n","# np.random.seed(3)\n","tf.random.set_seed(3)\n","\n","# Generator model\n","generator = Sequential()\n","generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(alpha=0.2)))  # GAN은 ReLU 학습이 다소 불안정 하기에 LeakyReLU사용\n","generator.add(BatchNormalization())  # 데이터 정규화 - 안정적 학습 :과적합 방지 효과\n","generator.add(Reshape((7,7,128)))\n","generator.add(UpSampling2D())  # 이미지 크기를 2배 확장\n","generator.add(Conv2D(64, kernel_size=5, padding='same'))\n","generator.add(BatchNormalization())\n","generator.add(Activation(LeakyReLU(0.3)))  # alpha = 음의 기울기 계수  -1 ~ 1 사이\n","generator.add(UpSampling2D())  # 이미지 크기를 2배 확장\n","generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n","\n","print(generator.summary())\n","\n","# Discriminator model\n","discriminator = Sequential()\n","discriminator.add(Conv2D(64, kernel_size=5, padding='same', strides=2, input_shape=(28, 28, 1)))\n","discriminator.add(Activation(LeakyReLU(0.2)))\n","discriminator.add(Conv2D(128, kernel_size=5, padding='same'))\n","discriminator.add(Activation(LeakyReLU(0.2)))\n","discriminator.add(Flatten())\n","discriminator.add(Dropout(0.3))\n","discriminator.add(Dense(1, activation='sigmoid'))\n","print(discriminator.summary())\n","\n","discriminator.compile(optimizer='adam', loss='binary_crossentropy')\n","discriminator.trainable = False"],"metadata":{"id":"Qoz0UMqZqZ2x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GAN 모델 생성\n","ginput = Input(shape=(100,))\n","dis_output = discriminator(generator(ginput))\n","gan = Model(ginput, dis_output)\n","\n","# GAN 모델 컴파일\n","gan.compile(optimizer='adam', loss='binary_crossentropy')\n","\n","# GAN 모델 요약 출력\n","print(gan.summary())\n"],"metadata":{"id":"gsV4ZmBRpgyE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 신경망 실행 함수\n","def gan_train(epoch, batch_size, saving_interval):\n","    (x_train, _),(x_test, _)= mnist.load_data()\n","    x_train = x_train.reshape(x_train.shape[0],28,28,1).astype('float32')\n","    x_train = (x_train-127.5)/127.5  #-1~1 사이 값으로 변경\n","\n","    true= np.ones((batch_size,1)) # batch_size는 한 번에 몇개의 실제이미지와 가짜이미지를 판별자에 넣을지 결정\n","    #먼저 batch_size 만큼 MNIST 이미지를 랜덤하게 불러와 판별자에 집어 넣는 과정이다. 실제이미지를 입력햇으므로 모두 참(1)\n","    fake = np.zeros((batch_size,1))\n","\n","    for i in range(epoch):\n","        idx= np.random.randint(0, x_train.shape[0], batch_size) # 실제 이미지를 랜덤하게 선택해 판별자에 입력\n","        imgs = x_train[idx]\n","        d_loss_real = discriminator.train_on_batch(imgs, true) # batch_size 만큼 판별 시작\n","\n","        # 가상 이미지를 판별자에 입력하기\n","        noise = np.random.normal(0,1,(batch_size, 100)) # 잠재 공간에서 무작위로 샘플링\n","        gen_imgs = generator.predict(noise)\n","        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake) # gen_imgs에 모두 가짜(0)라는 레이블이 붙음\n","\n","        # 판별자와 생성자의 오차를 계산\n","        d_loss = np.add(d_loss_real, d_loss_fake)*0.5\n","        g_loss = gan.train_on_batch(noise,true) # 판별자와 생성자를 연결해서 만든 gan모델을 이용해 생성자의 오차(g_loss)를 구함\n","        print('epoch:%d'%i,'d_loss=%.4f'%d_loss,' g_loss=%.4f'%g_loss) #생성자와 판별자의 오차 출력\n","\n","        if i % saving_interval == 0:\n","            noise = np.random.normal(0,1,(25,100)) #잠재공간에서 무작위로 샘플링\n","            gen_imgs = generator.predict(noise)\n","            gen_imgs = gen_imgs*0.5+0.5 # rescale : 0~1\n","\n","            fig, axs = plt.subplots(5,5)\n","            count = 0\n","            for j in range(5):\n","                for k in range(5):\n","                    axs[j,k].imshow(gen_imgs[count,:,:,0],cmap='gray')\n","                    axs[j,k].axis('off')\n","                    count +=1\n","                fig.savefig('gan_imgs/gmnist_%d.png'%i)\n","\n","    #descriminator의 wait값을 주는 것 학습은 generator만 하는 것\n","    #이미지가 실제 이미지와 가까워질것\n","gan_train(4001,32,200)\n"],"metadata":{"id":"UGaQjT-zqwSv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 생성적 적대 신경망"],"metadata":{"id":"dfAVYcFJ0hUi"},"execution_count":null,"outputs":[]}]}