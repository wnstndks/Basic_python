{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOviP+8fUuLnv1UusPKFJyo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#시퀀스-투-시퀀스(Sequence-to-Sequence, seq2seq)\n","는 입력된 시퀀스로부터 다른 도메인의 시퀀스를 출력하는 다양한 분야에서 사용되는 모델입니다. 예를 들어 챗봇(Chatbot)과 기계 번역(Machine Translation)이 그러한 대표적인 예인데, 입력 시퀀스와 출력 시퀀스를 각각 질문과 대답으로 구성하면 챗봇으로 만들 수 있고, 입력 시퀀스와 출력 시퀀스를 각각 입력 문장과 번역 문장으로 만들면 번역기로 만들 수 있습니다. 그 외에도 내용 요약(Text Summarization), STT(Speech to Text) 등에서 쓰일 수 있습니다."],"metadata":{"id":"k2TFtOmfm63D"}},{"cell_type":"markdown","source":["## 문자레벨 기계 번역기 구현\n","영어를 불어로 번역하기"],"metadata":{"id":"R-rorYwbndSR"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKOQOGjxmlRq","executionInfo":{"status":"ok","timestamp":1702347533870,"user_tz":-540,"elapsed":7648,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"97f8c142-cbad-4a14-f2e3-34f6e80de064"},"outputs":[{"output_type":"stream","name":"stdout","text":["ZIP file downloaded to fra-eng.zip\n","전체 샘플의 개수 : 229803\n"]}],"source":["import os\n","import shutil\n","import zipfile\n","\n","import pandas as pd\n","import tensorflow as tf\n","import urllib3\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","import requests\n","\n","headers = {\n","    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n","}\n","\n","def download_zip(url, output_path):\n","    response = requests.get(url, headers=headers, stream=True)\n","    if response.status_code == 200:\n","        with open(output_path, 'wb') as f:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                f.write(chunk)\n","        print(f\"ZIP file downloaded to {output_path}\")\n","    else:\n","        print(f\"Failed to download. HTTP Response Code: {response.status_code}\")\n","\n","url = \"http://www.manythings.org/anki/fra-eng.zip\"\n","output_path = \"fra-eng.zip\"\n","download_zip(url, output_path)\n","\n","path = os.getcwd()\n","zipfilename = os.path.join(path, output_path)\n","\n","with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n","    zip_ref.extractall(path)\n","lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n","del lines['lic']\n","print('전체 샘플의 개수 :',len(lines))"]},{"cell_type":"code","source":["lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n","del lines['lic']\n","print('전체 샘플의 개수 :',len(lines))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2On_ZktHsHOV","executionInfo":{"status":"ok","timestamp":1702347534782,"user_tz":-540,"elapsed":916,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"cdc694c9-7f26-47ce-d64d-13d587e49876"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플의 개수 : 229803\n"]}]},{"cell_type":"code","source":["lines = lines.loc[:, 'src':'tar']\n","lines = lines[0:60000] # 6만개만 저장\n","lines.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"yCPWyRYAt0JQ","executionInfo":{"status":"ok","timestamp":1702347535389,"user_tz":-540,"elapsed":611,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"d45e694d-8ea7-4be3-cfaa-7c8699e91b0d"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         src                                        tar\n","18582       What was inside?  Qu'est-ce qui se trouvait à l'intérieur ?\n","42020   I'm so proud of you.             Je suis tellement fier de toi.\n","47099  Don't break my heart.                 Ne me brisez pas le cœur !\n","21483      I'm freaking out.                                 Je flippe.\n","13940        You disgust me.                            Tu me dégoûtes.\n","16969       Nobody was home.                 Personne n'était chez moi.\n","48975  I need to take notes.                 Je dois prendre des notes.\n","26480     I could intervene.                     Je pouvais intervenir.\n","23045      They won the day.              Ils remportèrent la victoire.\n","40987   I know that feeling.                Je connais cette sensation."],"text/html":["\n","  <div id=\"df-cbe51fb9-b3f2-4f06-867b-871fd8bdd905\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>tar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>18582</th>\n","      <td>What was inside?</td>\n","      <td>Qu'est-ce qui se trouvait à l'intérieur ?</td>\n","    </tr>\n","    <tr>\n","      <th>42020</th>\n","      <td>I'm so proud of you.</td>\n","      <td>Je suis tellement fier de toi.</td>\n","    </tr>\n","    <tr>\n","      <th>47099</th>\n","      <td>Don't break my heart.</td>\n","      <td>Ne me brisez pas le cœur !</td>\n","    </tr>\n","    <tr>\n","      <th>21483</th>\n","      <td>I'm freaking out.</td>\n","      <td>Je flippe.</td>\n","    </tr>\n","    <tr>\n","      <th>13940</th>\n","      <td>You disgust me.</td>\n","      <td>Tu me dégoûtes.</td>\n","    </tr>\n","    <tr>\n","      <th>16969</th>\n","      <td>Nobody was home.</td>\n","      <td>Personne n'était chez moi.</td>\n","    </tr>\n","    <tr>\n","      <th>48975</th>\n","      <td>I need to take notes.</td>\n","      <td>Je dois prendre des notes.</td>\n","    </tr>\n","    <tr>\n","      <th>26480</th>\n","      <td>I could intervene.</td>\n","      <td>Je pouvais intervenir.</td>\n","    </tr>\n","    <tr>\n","      <th>23045</th>\n","      <td>They won the day.</td>\n","      <td>Ils remportèrent la victoire.</td>\n","    </tr>\n","    <tr>\n","      <th>40987</th>\n","      <td>I know that feeling.</td>\n","      <td>Je connais cette sensation.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbe51fb9-b3f2-4f06-867b-871fd8bdd905')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-cbe51fb9-b3f2-4f06-867b-871fd8bdd905 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-cbe51fb9-b3f2-4f06-867b-871fd8bdd905');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-29d9db88-a5e9-47fc-9a59-e6cefd2c1f67\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-29d9db88-a5e9-47fc-9a59-e6cefd2c1f67')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-29d9db88-a5e9-47fc-9a59-e6cefd2c1f67 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n","lines.sample(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"azRFdweCt2k5","executionInfo":{"status":"ok","timestamp":1702347535389,"user_tz":-540,"elapsed":11,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"192e3659-f008-4803-b3ab-8c91c82e77c9"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                          src                                      tar\n","3524             I'll attend.                    \\t J'y assisterai. \\n\n","42794    My mother called me.               \\t Ma mère m'a appelée. \\n\n","36470     They want you dead.          \\t Elles vous veulent morte. \\n\n","14904        He betrayed you.                \\t Il vous trahissait. \\n\n","10184          You won't win.              \\t Vous ne gagnerez pas. \\n\n","55741  He abandoned the idea.             \\t Il a abandonné l'idée. \\n\n","49619   I'll do it next week.  \\t Je le ferai la semaine prochaine. \\n\n","26642      I found a way out.             \\t J'ai trouvé une issue. \\n\n","41593    I went into details.        \\t J'entrais dans les détails. \\n\n","18564        What is missing?             \\t Qu'est-ce qui manque ? \\n"],"text/html":["\n","  <div id=\"df-59dd1488-3b9c-4b09-87c0-25db72336efd\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>tar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3524</th>\n","      <td>I'll attend.</td>\n","      <td>\\t J'y assisterai. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>42794</th>\n","      <td>My mother called me.</td>\n","      <td>\\t Ma mère m'a appelée. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>36470</th>\n","      <td>They want you dead.</td>\n","      <td>\\t Elles vous veulent morte. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>14904</th>\n","      <td>He betrayed you.</td>\n","      <td>\\t Il vous trahissait. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>10184</th>\n","      <td>You won't win.</td>\n","      <td>\\t Vous ne gagnerez pas. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>55741</th>\n","      <td>He abandoned the idea.</td>\n","      <td>\\t Il a abandonné l'idée. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>49619</th>\n","      <td>I'll do it next week.</td>\n","      <td>\\t Je le ferai la semaine prochaine. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>26642</th>\n","      <td>I found a way out.</td>\n","      <td>\\t J'ai trouvé une issue. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>41593</th>\n","      <td>I went into details.</td>\n","      <td>\\t J'entrais dans les détails. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>18564</th>\n","      <td>What is missing?</td>\n","      <td>\\t Qu'est-ce qui manque ? \\n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59dd1488-3b9c-4b09-87c0-25db72336efd')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-59dd1488-3b9c-4b09-87c0-25db72336efd button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-59dd1488-3b9c-4b09-87c0-25db72336efd');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d78d29bf-ba58-4f14-aca0-9f5e2c849b03\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d78d29bf-ba58-4f14-aca0-9f5e2c849b03')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d78d29bf-ba58-4f14-aca0-9f5e2c849b03 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["# 문자 집합 구축\n","src_vocab = set()\n","for line in lines.src: # 1줄씩 읽음\n","    for char in line: # 1개의 문자씩 읽음\n","        src_vocab.add(char)\n","\n","tar_vocab = set()\n","for line in lines.tar:\n","    for char in line:\n","        tar_vocab.add(char)\n","\n","src_vocab_size = len(src_vocab)+1\n","tar_vocab_size = len(tar_vocab)+1\n","print('source 문장의 char 집합 :',src_vocab_size)\n","print('target 문장의 char 집합 :',tar_vocab_size)\n","\n","src_vocab = sorted(list(src_vocab))\n","tar_vocab = sorted(list(tar_vocab))\n","print(src_vocab[60:80])\n","print(tar_vocab[90:104])\n","\n","src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n","tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n","print(src_to_index)\n","print(tar_to_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xvms2Xmst5xJ","executionInfo":{"status":"ok","timestamp":1702347535734,"user_tz":-540,"elapsed":354,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"27c0e1a2-6e94-43f5-e602-637e05a6f760"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["source 문장의 char 집합 : 80\n","target 문장의 char 집합 : 104\n","['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'é', 'ï', '’', '€']\n","['ê', 'ë', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '\\u2009', '‘', '’', '\\u202f', '‽']\n","{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, 'ï': 77, '’': 78, '€': 79}\n","{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'a': 52, 'b': 53, 'c': 54, 'd': 55, 'e': 56, 'f': 57, 'g': 58, 'h': 59, 'i': 60, 'j': 61, 'k': 62, 'l': 63, 'm': 64, 'n': 65, 'o': 66, 'p': 67, 'q': 68, 'r': 69, 's': 70, 't': 71, 'u': 72, 'v': 73, 'w': 74, 'x': 75, 'y': 76, 'z': 77, '\\xa0': 78, '«': 79, '»': 80, 'À': 81, 'Ç': 82, 'É': 83, 'Ê': 84, 'Ô': 85, 'à': 86, 'â': 87, 'ç': 88, 'è': 89, 'é': 90, 'ê': 91, 'ë': 92, 'î': 93, 'ï': 94, 'ô': 95, 'ù': 96, 'û': 97, 'œ': 98, '\\u2009': 99, '‘': 100, '’': 101, '\\u202f': 102, '‽': 103}\n"]}]},{"cell_type":"code","source":["encoder_input = []\n","\n","# 1개의 문장\n","for line in lines.src:\n","  encoded_line = []\n","  # 각 줄에서 1개의 char\n","  for char in line:\n","    # 각 char을 정수로 변환\n","    encoded_line.append(src_to_index[char])\n","  encoder_input.append(encoded_line)\n","print('source 문장의 정수 인코딩 :',encoder_input[:5])\n","\n","decoder_input = []\n","for line in lines.tar:\n","  encoded_line = []\n","  for char in line:\n","    encoded_line.append(tar_to_index[char])\n","  decoder_input.append(encoded_line)\n","print('target 문장의 정수 인코딩 :',decoder_input[:5])\n","\n","# 정수 인코딩 과정에서 <sos>를 제거합니다. 즉, 모든 프랑스어 문장의 맨 앞에 붙어있는 '\\t'를 제거하도록 합니다.\n","# RNN을 두개사용하는데 병렬로 연결한 것뿐\n","decoder_target = []\n","for line in lines.tar:\n","  timestep = 0\n","  encoded_line = []\n","  for char in line:\n","    if timestep > 0:\n","      encoded_line.append(tar_to_index[char])\n","    timestep = timestep + 1\n","  decoder_target.append(encoded_line)\n","print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C089kxTRt9JC","executionInfo":{"status":"ok","timestamp":1702347538181,"user_tz":-540,"elapsed":2450,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"c5bc887f-9ee0-4738-cace-95b6b74d9bb2"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n","target 문장의 정수 인코딩 : [[1, 3, 48, 52, 3, 4, 3, 2], [1, 3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [1, 3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [1, 3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [1, 3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n","target 문장 레이블의 정수 인코딩 : [[3, 48, 52, 3, 4, 3, 2], [3, 39, 52, 69, 54, 59, 56, 14, 3, 2], [3, 31, 65, 3, 69, 66, 72, 71, 56, 3, 4, 3, 2], [3, 28, 66, 72, 58, 56, 3, 4, 3, 2], [3, 45, 52, 63, 72, 71, 3, 4, 3, 2]]\n"]}]},{"cell_type":"code","source":["# 패딩을 위해서 영어 문장과 프랑스어 문장 각각에 대해서 가장 길이가 긴 샘플의 길이를 확인합니다.\n","\n","max_src_len = max([len(line) for line in lines.src])\n","max_tar_len = max([len(line) for line in lines.tar])\n","print('source 문장의 최대 길이 :',max_src_len) # 22\n","print('target 문장의 최대 길이 :',max_tar_len) # 76\n","\n","# 가장 긴 샘플의 길이에 맞춰서 영어 데이터의 샘플은 전부 길이가 23이 되도록 패딩하고, 프랑스어 데이터의 샘플은 전부 길이가 76이 되도록 패딩합니다.\n","\n","encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n","decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n","decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n","\n","# 모든 값에 대해서 원-핫 인코딩을 수행합니다. 문자 단위 번역기므로 워드 임베딩은 별도로 사용되지 않으며, 예측값과의 오차 측정에 사용되는 실제값뿐만 아니라 입력값도 원-핫 벡터를 사용하겠습니다.\n","\n","encoder_input = to_categorical(encoder_input)\n","decoder_input = to_categorical(decoder_input)\n","decoder_target = to_categorical(decoder_target)\n","\n","print(encoder_input[:1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5SaEO6JRwimT","executionInfo":{"status":"ok","timestamp":1702347542570,"user_tz":-540,"elapsed":4394,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"7615f56e-d1ab-4e72-eb81-479ce6e160c3"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["source 문장의 최대 길이 : 22\n","target 문장의 최대 길이 : 76\n","[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]\n","  [1. 0. 0. ... 0. 0. 0.]]]\n"]}]},{"cell_type":"code","source":["# seq2seq 모델을 설계하고 교사 강요를 사용하여 훈련시켜보도록 하겠습니다.\n","# Sequentail API를 못기에 functional api 사용 - 입력값이 복수개이기 때문\n","\n","from keras.layers import Input, LSTM, Embedding, Dense\n","from keras.models import Model\n","import numpy as np\n","encoder_inputs = Input(shape=(None, src_vocab_size))\n","encoder_lstm = LSTM(units=256, return_state=True) #return_state=True로 설정합니다. 인코더에 입력을 넣으면 내부 상태를 리턴합니다.\n","\n","# encoder_outputs은 여기서는 불필요 셀상태 -> LSTM이라서 이전 값을 기억하는 망각게이트가 있는데 이게 state_c임\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","\n","# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n","encoder_states = [state_h, state_c] # 얘가 context vector -> 학습시 여기까지 작업이 이루어짐\n","\n","#------ 인코더 끝 디코 시작 ------------\n","\n","# encoder_states를 디코더에 전달하므로서 이 두 가지 상태 모두를 디코더로 전달합니다. 이것이 앞서 배운 컨텍스트 벡터입니다.\n","\n","decoder_inputs = Input(shape=(None, tar_vocab_size))\n","decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n","\n","# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n","decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n","\n","decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n","decoder_outputs = decoder_softmax_layer(decoder_outputs)\n","\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\") #adam을 사용해도 좋음\n","\n","print(model.summary())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZmzLxEr_xAjb","executionInfo":{"status":"ok","timestamp":1702347546658,"user_tz":-540,"elapsed":4107,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"1f92320c-c055-4cdf-8cae-afb6e6610187"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, None, 80)]           0         []                            \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, None, 104)]          0         []                            \n","                                                                                                  \n"," lstm (LSTM)                 [(None, 256),                345088    ['input_1[0][0]']             \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," lstm_1 (LSTM)               [(None, None, 256),          369664    ['input_2[0][0]',             \n","                              (None, 256),                           'lstm[0][1]',                \n","                              (None, 256)]                           'lstm[0][2]']                \n","                                                                                                  \n"," dense (Dense)               (None, None, 104)            26728     ['lstm_1[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 741480 (2.83 MB)\n","Trainable params: 741480 (2.83 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","None\n"]}]},{"cell_type":"code","source":["#학습시킴\n","model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HpqqX3tR0QyU","executionInfo":{"status":"ok","timestamp":1702348165791,"user_tz":-540,"elapsed":571999,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"0c3fb30a-07d5-4c27-d828-ad65dcbb1ad6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","750/750 [==============================] - 20s 17ms/step - loss: 0.8472 - val_loss: 0.7742\n","Epoch 2/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.5722 - val_loss: 0.6583\n","Epoch 3/50\n","750/750 [==============================] - 10s 13ms/step - loss: 0.5039 - val_loss: 0.6016\n","Epoch 4/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.4572 - val_loss: 0.5527\n","Epoch 5/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.4226 - val_loss: 0.5179\n","Epoch 6/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.3964 - val_loss: 0.4942\n","Epoch 7/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.3762 - val_loss: 0.4757\n","Epoch 8/50\n","750/750 [==============================] - 10s 13ms/step - loss: 0.3594 - val_loss: 0.4538\n","Epoch 9/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.3454 - val_loss: 0.4432\n","Epoch 10/50\n","750/750 [==============================] - 11s 15ms/step - loss: 0.3338 - val_loss: 0.4335\n","Epoch 11/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.3235 - val_loss: 0.4195\n","Epoch 12/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.3144 - val_loss: 0.4110\n","Epoch 13/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.3064 - val_loss: 0.4039\n","Epoch 14/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2990 - val_loss: 0.3989\n","Epoch 15/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2926 - val_loss: 0.3908\n","Epoch 16/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2865 - val_loss: 0.3872\n","Epoch 17/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2808 - val_loss: 0.3835\n","Epoch 18/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2755 - val_loss: 0.3760\n","Epoch 19/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2706 - val_loss: 0.3721\n","Epoch 20/50\n","750/750 [==============================] - 11s 15ms/step - loss: 0.2660 - val_loss: 0.3710\n","Epoch 21/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2616 - val_loss: 0.3667\n","Epoch 22/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2574 - val_loss: 0.3634\n","Epoch 23/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2536 - val_loss: 0.3620\n","Epoch 24/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2498 - val_loss: 0.3589\n","Epoch 25/50\n","750/750 [==============================] - 10s 13ms/step - loss: 0.2462 - val_loss: 0.3569\n","Epoch 26/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2431 - val_loss: 0.3558\n","Epoch 27/50\n","750/750 [==============================] - 11s 15ms/step - loss: 0.2398 - val_loss: 0.3531\n","Epoch 28/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2367 - val_loss: 0.3525\n","Epoch 29/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2337 - val_loss: 0.3518\n","Epoch 30/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2309 - val_loss: 0.3512\n","Epoch 31/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2281 - val_loss: 0.3481\n","Epoch 32/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2255 - val_loss: 0.3477\n","Epoch 33/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2230 - val_loss: 0.3477\n","Epoch 34/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2204 - val_loss: 0.3459\n","Epoch 35/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2181 - val_loss: 0.3457\n","Epoch 36/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2157 - val_loss: 0.3442\n","Epoch 37/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2135 - val_loss: 0.3449\n","Epoch 38/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2113 - val_loss: 0.3457\n","Epoch 39/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2092 - val_loss: 0.3433\n","Epoch 40/50\n","750/750 [==============================] - 12s 16ms/step - loss: 0.2072 - val_loss: 0.3426\n","Epoch 41/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2051 - val_loss: 0.3443\n","Epoch 42/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.2031 - val_loss: 0.3430\n","Epoch 43/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.2012 - val_loss: 0.3445\n","Epoch 44/50\n","750/750 [==============================] - 11s 15ms/step - loss: 0.1994 - val_loss: 0.3428\n","Epoch 45/50\n","750/750 [==============================] - 11s 15ms/step - loss: 0.1975 - val_loss: 0.3438\n","Epoch 46/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.1957 - val_loss: 0.3444\n","Epoch 47/50\n","750/750 [==============================] - 12s 16ms/step - loss: 0.1940 - val_loss: 0.3431\n","Epoch 48/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.1924 - val_loss: 0.3434\n","Epoch 49/50\n","750/750 [==============================] - 11s 14ms/step - loss: 0.1906 - val_loss: 0.3446\n","Epoch 50/50\n","750/750 [==============================] - 10s 14ms/step - loss: 0.1891 - val_loss: 0.3460\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x78d3ccd883d0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["# 기계 번역을 하도록 모델을 조정하고 동작시켜보도록 하겠습니다.\n","\n","# 전체적인 번역 동작 단계를 정리하면 아래와 같습니다.\n","# 1. 번역하고자 하는 입력 문장이 인코더에 들어가서 은닉 상태와 셀 상태를 얻습니다.\n","# 2. 상태와 <SOS>에 해당하는 \\t를 디코더로 보냅니다.\n","# 3. 디코더가 <EOS>에 해당하는 \\n이 나올 때까지 다음 문자를 예측하는 행동을 반복합니다.\n","\n","#인코더 모델\n","encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n","\n","#디코더를 정의\n","# 이전 시점의 상태들을 저장하는 텐서\n","decoder_state_input_h = Input(shape=(256,))\n","decoder_state_input_c = Input(shape=(256,))\n","decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n","\n","# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n","# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n","\n","# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n","decoder_states = [state_h, state_c]\n","decoder_outputs = decoder_softmax_layer(decoder_outputs)\n","decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n","\n","# 단어로부터 인덱스를 얻는 것이 아니라 인덱스로부터 단어를 얻을 수 있는 index_to_src와 index_to_tar를 만들었습니다.\n","index_to_src = dict((i, char) for char, i in src_to_index.items())\n","index_to_tar = dict((i, char) for char, i in tar_to_index.items())\n","\n","print(index_to_src)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdJO9Vpq0tV6","executionInfo":{"status":"ok","timestamp":1702349110885,"user_tz":-540,"elapsed":346,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"028b69fd-463c-4249-cbf6-6933e128127b"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["{1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: ',', 9: '-', 10: '.', 11: '/', 12: '0', 13: '1', 14: '2', 15: '3', 16: '4', 17: '5', 18: '6', 19: '7', 20: '8', 21: '9', 22: ':', 23: '?', 24: 'A', 25: 'B', 26: 'C', 27: 'D', 28: 'E', 29: 'F', 30: 'G', 31: 'H', 32: 'I', 33: 'J', 34: 'K', 35: 'L', 36: 'M', 37: 'N', 38: 'O', 39: 'P', 40: 'Q', 41: 'R', 42: 'S', 43: 'T', 44: 'U', 45: 'V', 46: 'W', 47: 'X', 48: 'Y', 49: 'Z', 50: 'a', 51: 'b', 52: 'c', 53: 'd', 54: 'e', 55: 'f', 56: 'g', 57: 'h', 58: 'i', 59: 'j', 60: 'k', 61: 'l', 62: 'm', 63: 'n', 64: 'o', 65: 'p', 66: 'q', 67: 'r', 68: 's', 69: 't', 70: 'u', 71: 'v', 72: 'w', 73: 'x', 74: 'y', 75: 'z', 76: 'é', 77: 'ï', 78: '’', 79: '€'}\n"]}]},{"cell_type":"code","source":["def decode_sequence(input_seq):\n","  # 입력으로부터 인코더의 상태를 얻음\n","  states_value = encoder_model.predict(input_seq)\n","\n","  # <SOS>에 해당하는 원-핫 벡터 생성\n","  target_seq = np.zeros((1, 1, tar_vocab_size))\n","  target_seq[0, 0, tar_to_index['\\t']] = 1.\n","\n","  stop_condition = False\n","  decoded_sentence = \"\"\n","\n","  # stop_condition이 True가 될 때까지 루프 반복\n","  while not stop_condition:\n","    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n","    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n","\n","    # 예측 결과를 문자로 변환\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_char = index_to_tar[sampled_token_index]\n","\n","    # 현재 시점의 예측 문자를 예측 문장에 추가\n","    decoded_sentence += sampled_char\n","\n","    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n","    if (sampled_char == '\\n' or\n","        len(decoded_sentence) > max_tar_len):\n","        stop_condition = True\n","\n","    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n","    target_seq = np.zeros((1, 1, tar_vocab_size))\n","    target_seq[0, 0, sampled_token_index] = 1.\n","\n","    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n","    states_value = [h, c]\n","\n","  return decoded_sentence\n","for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n","  input_seq = encoder_input[seq_index:seq_index+1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print(35 * \"-\")\n","  print('입력 문장:', lines.src[seq_index])\n","  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n","  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0vALcHTG6flV","executionInfo":{"status":"ok","timestamp":1702349122340,"user_tz":-540,"elapsed":6815,"user":{"displayName":"안준수","userId":"00601706101805679007"}},"outputId":"b8fb8e82-2158-4fa0-e3c7-4db923fc066f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 353ms/step\n","1/1 [==============================] - 0s 356ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 20ms/step\n","-----------------------------------\n","입력 문장: Go.\n","정답 문장: Bouge ! \n","번역 문장: Attrape ! \n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 32ms/step\n","-----------------------------------\n","입력 문장: Hello!\n","정답 문장: Bonjour ! \n","번역 문장: Sons pour moi. \n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 33ms/step\n","1/1 [==============================] - 0s 36ms/step\n","1/1 [==============================] - 0s 32ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 39ms/step\n","1/1 [==============================] - 0s 28ms/step\n","1/1 [==============================] - 0s 35ms/step\n","1/1 [==============================] - 0s 29ms/step\n","1/1 [==============================] - 0s 30ms/step\n","1/1 [==============================] - 0s 34ms/step\n","1/1 [==============================] - 0s 31ms/step\n","1/1 [==============================] - 0s 37ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","-----------------------------------\n","입력 문장: Got it!\n","정답 문장: J'ai pigé ! \n","번역 문장: Attrape ça. \n","1/1 [==============================] - 0s 17ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 18ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 21ms/step\n","-----------------------------------\n","입력 문장: Go home.\n","정답 문장: Rentre à la maison. \n","번역 문장: Allez au lit ! \n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 19ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 20ms/step\n","1/1 [==============================] - 0s 19ms/step\n","-----------------------------------\n","입력 문장: Get going.\n","정답 문장: En avant. \n","번역 문장: Dégage ! \n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"UDxZC0QY6g67"},"execution_count":null,"outputs":[]}]}