{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOTfVmB4bj6Mbr+Pv3AMwbg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 스팸메일 분류(이항분류) : LSTM 사용\n","many to one"],"metadata":{"id":"dUlUUh417Py9"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_ZWsOxnl7NnJ"},"outputs":[],"source":["import pandas as pd\n","\n","data=pd.read_csv('https://raw.githubusercontent.com/pykwon/python/master/testdata_utf8/spam.csv',encoding='latin1')\n","print(data.head(3))\n","del data['Unnamed: 2']\n","del data['Unnamed: 3']\n","del data['Unnamed: 4']\n","print(data.head(3))\n","print()\n","\n","data['v1']=data['v1'].replace(['ham','spam'],[0,1])\n","print(data.head(3))\n","print(data.info())\n","print(data.isnull().values.any())\n","\n"]},{"cell_type":"code","source":["print(data['v2'].nunique()) # 전체 5572 중 5169만 unique -\n","# 중복 메일 제거하기\n","data.drop_duplicates(subset=['v2'], inplace=True)\n","print('행 수 : ',len(data))\n","print(data['v1'].value_counts()) #0 4516 1 653\n","print(data.groupby('v1').size().reset_index(name='count'))\n","\n","x_data=data['v2'] #메일 내용(feature)\n","y_data=data['v1'] #메일 구분 (label)\n","\n","#feature에 대한 토큰 처리\n","from keras.preprocessing.text import Tokenizer\n","tok= Tokenizer() #char_level=False :단어(기본) , char_level=True : 글자\n","tok.fit_on_texts(x_data)\n","sequences = tok.texts_to_sequences(x_data)\n","print(sequences[:3])\n","\n","word_to_index = tok.word_index\n","print(word_to_index) #{'i': 1, 'to': 2, 'you': 3, 'a': 4, 'the': 5,\n","print(x_data[:1]) # Go until jurong point, crazy.. Available only ...\n","\n","vocab_size = len(word_to_index) + 1 # 패딩을 위한 0번 단어를 고려해 +1을 해서 저장함\n","print('vocab_size : ', vocab_size) #8921\n","\n","x_data = sequences\n","print('max len : ', max(len(i) for i in x_data)) # max len :  189\n","print('avg len : ', (sum(map(len, x_data))/len(x_data))) # avg len :  15.610369510543626"],"metadata":{"id":"z6OsFlKY7n-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.utils import pad_sequences\n","max_len = max(len(i) for i in x_data)\n","data=pad_sequences(x_data, maxlen=max_len)\n","print(data[:1])\n","\n","# train, test split\n","n_of_train = int(len(sequences)*0.8)\n","n_of_test = int(len(sequences)-n_of_train)\n","print('n_of_train :',n_of_train)\n","print('n_of_test :',n_of_test)\n","\n","import numpy as np\n","x_train = data[:n_of_train]\n","y_train= np.array(y_data[:n_of_train])\n","x_test = data[n_of_train:]\n","y_test = np.array(y_data[n_of_train:])\n","print(x_train.shape, y_train.shape,x_test.shape, y_test.shape) #(4135, 189) (4135,) (1034, 189) (1034,)\n","print(x_train[:2])\n","print(y_train[:2])"],"metadata":{"id":"w2qTZKc7-dym"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#model : LSTM + Dense\n","\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Embedding, Dropout\n","\n","model= Sequential()\n","model.add(Embedding(vocab_size,32))\n","model.add(LSTM(units=32, activation='tanh'))\n","model.add(Dense(units=32, activation='relu'))\n","model.add(Dropout(rate=0.2))\n","model.add(Dense(units=1,activation='sigmoid'))\n","\n","print(model.summary())\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","history=model.fit(x=x_train,y=y_train, batch_size=32,epochs=5, validation_split=0.2,verbose=2)"],"metadata":{"id":"bNyDCeRwC-h1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('test로 검증된 분류 정확도 : %.3f'%(model.evaluate(x_test,y_test)[1]))\n","\n","import matplotlib.pyplot as plt\n","# 시각화\n","epochs= range(1,len(history.history['acc'])+1)\n","\n","plt.plot(epochs, history.history['acc'], label='accuracy', color='red')\n","plt.plot(epochs, history.history['val_acc'], label='val_accuracy', color='orange')\n","plt.ylabel('acc')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(epochs, history.history['loss'], label='loss', color='indigo')\n","plt.plot(epochs, history.history['val_loss'], label='val_loss', color='blue')\n","plt.ylabel('loss')\n","plt.legend()\n","plt.show()\n","\n","#---------위에까지는 이항분류-------\n","\n","#pred\n","pred= model.predict(x_test[:20])\n","print('예측값 : ', np.where(pred>0.5,1,0).flatten())\n","print('실제값 : ',y_test[:20])"],"metadata":{"id":"zD3bpNzWF6H4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"zz9xEs2iHo9h"},"execution_count":null,"outputs":[]}]}