{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP8eDAsSpglagciA7niyPaJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# LSTM + Dense 모델을 작성해 주가 예측\n","삼성전자 증권표준코드 005930 를 이용해서 주가 예측\n","\n","\n"],"metadata":{"id":"8Vk7mnyJuoUy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"PcQQQtTKskDv"},"outputs":[],"source":["!pip install finance-datareader"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import FinanceDataReader as fdr\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"0jiNrGL0vWtg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["STOCK_CODE='005930'\n","stock_data=fdr.DataReader(STOCK_CODE)\n","\n","print(stock_data.head(3))\n","print(stock_data.tail(3))\n","print()\n","\n","print('상관관계 : ',stock_data.corr())\n","print()\n","\n","stock_data.reset_index(inplace=True)\n","print(stock_data.head(3))\n","print()\n","\n","stock_data.drop(['Change'], axis='columns',inplace=True)\n","print(stock_data.head(3))\n","print()\n","\n","print(stock_data.info())\n","\n","# OLS, 분류- 집단위 나눠질때는 집단 평균차이를 확인할때는 ttest, anova, 빈도차이는 독립성? 선호도- 카이스퀘어,\n","# 가설검정, 기술통계는 반드시 집어넣주어야 한다- 데이터의 전체적인 내용을 확인해야 되니까\n","# 추론통계로 들어와서 regression, classification 이 있는데 가설검정이 있다치면 가설검정도 넣어주고, 딥러닝을 사용하기에 리그레션도 LSTM없이 할수 있음\n","# 텐서플로또한 LSTM을 넣어서 운영할 수 있다."],"metadata":{"id":"Ge8L0XsswMUp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Date열을 이용해 연도별 주가 변동 시각화\n","\n","Date열을 연,월,일로 분리해 새로운 열을 추가"],"metadata":{"id":"G4BCKSRn0Lh0"}},{"cell_type":"code","source":["stock_data['year']=stock_data['Date'].dt.year\n","stock_data['month']=stock_data['Date'].dt.month\n","stock_data['day']=stock_data['Date'].dt.day\n","print(stock_data.head(3))\n","print(stock_data.shape)\n","\n","df=stock_data.loc[stock_data['year']>=2000]\n","plt.figure(figsize=(6,4))\n","sns.lineplot(y=df['Close'],x=df.year)\n","plt.xlabel('time')\n","plt.ylabel('price')\n","plt.show()"],"metadata":{"id":"zhAa3hsMwwj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 전처리 계속 : Open High Low Close Volumne\n","from sklearn.preprocessing import MinMaxScaler\n","\n","scaler = MinMaxScaler()\n","scale_cols = ['Open','High','Low','Close','Volume']\n","df_scaled = scaler.fit_transform(stock_data[scale_cols])\n","df_scaled= pd.DataFrame(df_scaled)\n","df_scaled.columns=scale_cols\n","print(df_scaled.head(3))\n","\n","col_close=['Close']\n","close_scaled=scaler.fit_transform(stock_data[col_close])\n","print('스케일 값: ', close_scaled[:5].ravel())\n","print('스케일 원복 값: ', scaler.inverse_transform(close_scaled[:5]).ravel())\n","\n","# 과거 20일을 기준으로 그 다음날의 종가를 예측, 전체 데이터는 과거 200일 기준, 예측 기준은 과거 20일 사용\n","TEST_SIZE=200\n","train=df_scaled[:-TEST_SIZE]\n","test=df_scaled[-TEST_SIZE:]\n","print(train.shape) # (5800, 4)\n","print(test.shape) # (200, 4)\n","\n","# dataset 작성 함수\n","def make_dataset_func(data, label, window_size=20):\n","    feature_list = []\n","    label_list = []\n","    for i in range(len(data) - window_size):\n","        feature_list.append(np.array(data.iloc[i:i + window_size]))\n","        label_list.append(np.array(label.iloc[i + window_size]))\n","    return np.array(feature_list), np.array(label_list) #순차적으로 20일동안의 data를 묶어 label과 함께 대응하는 label과 함께 반환\n","\n","feature_cols = ['Open','High','Low','Volume']\n","label_cols=['Close']\n","\n","train_feature = train[feature_cols]\n","train_label = train[label_cols]\n","\n","test_feature = test[feature_cols]\n","test_label = test[label_cols]\n","print(train_feature[:3])\n","print(train_label[:3])\n","print(train_feature.shape, train_label.shape, test_feature.shape, test_label.shape)\n","\n","train_feature,train_label = make_dataset_func(train_feature, train_label)\n","print(train_feature[:2],train_label[:2])\n","print()\n","\n","# train_test split\n","from sklearn.model_selection import train_test_split\n","x_train,x_test, y_train,y_test = train_test_split(train_feature,train_label,test_size=0.2,random_state=12,shuffle=False)\n","print(x_train.shape, x_test.shape, y_train.shape, y_test.shape) #(4624, 20, 4) (1156, 20, 4) (4624, 1) (1156, 1)\n","\n","# test\n","test_feature,test_label = make_dataset_func(test_feature, test_label)\n","print(test_feature[:2],test_label[:2])\n","print(test_feature.shape,test_label.shape)\n"],"metadata":{"id":"gZsIJBwz0jsD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","model=Sequential()\n","model.add(LSTM(units=16,activation='tanh',input_shape=(train_feature.shape[1],train_feature.shape[2]),return_sequences=False)) # many-to-one #하나로 나가야 하기때문에 return sequences는 false, 많이 나가면 many to many\n","\n","model.add(Dense(units=16, activation='relu'))\n","model.add(Dense(units=1))\n","print( model.summary())\n"],"metadata":{"id":"lOTcuXXy8DkJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.losses import Huber\n","model.compile(optimizer='adam',loss=Huber(),metrics=['mse'])\n","# Huber loss는 모든 지점에서 미분이 가능하면서 이상치에 강건한(robust) 성격을 보이는 loss function이다 - 이상치에 덜 민감\n","\n","es=EarlyStopping(monitor='val_loss', patience=30)\n","chkPoint=ModelCheckpoint('tf33.hdf5', monitor='val_loss',save_best_only=True,mode='auto',verbose=0)\n","history=model.fit(x_train,y_train,epochs=100, batch_size=8, validation_data=(x_test,y_test),verbose=2,callbacks=[es,chkPoint])\n"],"metadata":{"id":"1yzxy81jB61P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(6,4))\n","plt.plot(history.history['loss'],label='loss')\n","plt.plot(history.history['val_loss'],label='val_loss',c='red')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"4hLj66qvMtyY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","model= keras.models.load_model('tf33.hdf5')\n","\n","pred=model.predict(test_feature,verbose=0)\n","\n","from sklearn.metrics import r2_score\n","print('r2_score : ',r2_score(test_label,pred))\n","\n","print('pred : ',np.round(pred[:10].flatten(),2))\n","print('real : ',np.round(test_label[:10].flatten(),2))\n","print('pred :', scaler.inverse_transform(pred[:10]).flatten())\n","print('real :', scaler.inverse_transform(test_label[:10]).flatten())\n","\n","#실제값, 예측값 시각화\n","plt.figure(figsize=(6,4))\n","plt.plot(test_label[:20],label='real')\n","plt.plot(pred[:20].flatten(),label='pred',c='red')\n","plt.legend()\n","plt.show()\n","#실제값과 예측값이 패턴을 잘 찾고 있다.\n"],"metadata":{"id":"kg5GNAmGNDRG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"xneef4NaOgjC"},"execution_count":null,"outputs":[]}]}