{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOB90GpyG3wAPphIX1kdLCG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# CycleGAN\n","\n","CycleGAN은 주기 일관성 손실을 사용하여 쌍으로 연결된 데이터 없이도 훈련을 수행할 수 있습니다. 즉, 소스와 대상 도메인 사이에서 일대일 매핑 없이 한 도메인에서 다른 도메인으로 변환할 수 있습니다.\n","\n","https://www.tensorflow.org/tutorials/generative/cyclegan?hl=ko"],"metadata":{"id":"rwcoJSQa5yaB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxuDA-n65fQg"},"outputs":[],"source":["pip install git+https://github.com/tensorflow/examples.git"]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow_examples.models.pix2pix import pix2pix\n","\n","import os\n","import time\n","import matplotlib.pyplot as plt\n","from IPython.display import clear_output\n","\n","AUTOTUNE = tf.data.AUTOTUNE"],"metadata":{"id":"b-UJ10Y86Le6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset, metadata = tfds.load('cycle_gan/horse2zebra',\n","                              with_info=True, as_supervised=True)\n","\n","train_horses, train_zebras = dataset['trainA'], dataset['trainB']\n","test_horses, test_zebras = dataset['testA'], dataset['testB']"],"metadata":{"id":"GIADWvZj6ODg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BUFFER_SIZE = 1000\n","BATCH_SIZE = 1\n","IMG_WIDTH = 256\n","IMG_HEIGHT = 256"],"metadata":{"id":"zFodmTit6PNi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def random_crop(image):\n","  cropped_image = tf.image.random_crop(\n","      image, size=[IMG_HEIGHT, IMG_WIDTH, 3])\n","\n","  return cropped_image\n","\n","# normalizing the images to [-1, 1]\n","def normalize(image):\n","  image = tf.cast(image, tf.float32)\n","  image = (image / 127.5) - 1\n","  return image\n","\n","def random_jitter(image):\n","  # resizing to 286 x 286 x 3\n","  image = tf.image.resize(image, [286, 286],\n","                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n","\n","  # randomly cropping to 256 x 256 x 3\n","  image = random_crop(image)\n","\n","  # random mirroring\n","  image = tf.image.random_flip_left_right(image)\n","\n","  return image\n","\n","def preprocess_image_train(image, label):\n","  image = random_jitter(image)\n","  image = normalize(image)\n","  return image\n","\n","def preprocess_image_test(image, label):\n","  image = normalize(image)\n","  return image"],"metadata":{"id":"Y1lRj5ug6RJM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_horses = train_horses.cache().map(\n","    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n","    BUFFER_SIZE).batch(BATCH_SIZE)\n","\n","train_zebras = train_zebras.cache().map(\n","    preprocess_image_train, num_parallel_calls=AUTOTUNE).shuffle(\n","    BUFFER_SIZE).batch(BATCH_SIZE)\n","\n","test_horses = test_horses.map(\n","    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n","    BUFFER_SIZE).batch(BATCH_SIZE)\n","\n","test_zebras = test_zebras.map(\n","    preprocess_image_test, num_parallel_calls=AUTOTUNE).cache().shuffle(\n","    BUFFER_SIZE).batch(BATCH_SIZE)"],"metadata":{"id":"Gwq1Ot206aB6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_horse = next(iter(train_horses))\n","sample_zebra = next(iter(train_zebras))"],"metadata":{"id":"_rjNrlY-6dKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.subplot(121)\n","plt.title('Horse')\n","plt.imshow(sample_horse[0] * 0.5 + 0.5)\n","\n","plt.subplot(122)\n","plt.title('Horse with random jitter')\n","plt.imshow(random_jitter(sample_horse[0]) * 0.5 + 0.5)"],"metadata":{"id":"X6m66BNC6e-V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pix2Pix 모델 가져오기 및 재사용하기"],"metadata":{"id":"Ijc10UB26n0J"}},{"cell_type":"code","source":["OUTPUT_CHANNELS = 3\n","\n","generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n","\n","discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n","discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"],"metadata":{"id":"2ckTz-5k6g31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["to_zebra = generator_g(sample_horse)\n","to_horse = generator_f(sample_zebra)\n","plt.figure(figsize=(8, 8))\n","contrast = 8\n","\n","imgs = [sample_horse, to_zebra, sample_zebra, to_horse]\n","title = ['Horse', 'To Zebra', 'Zebra', 'To Horse']\n","\n","for i in range(len(imgs)):\n","  plt.subplot(2, 2, i+1)\n","  plt.title(title[i])\n","  if i % 2 == 0:\n","    plt.imshow(imgs[i][0] * 0.5 + 0.5)\n","  else:\n","    plt.imshow(imgs[i][0] * 0.5 * contrast + 0.5)\n","plt.show()"],"metadata":{"id":"yjFMp4qz6rwD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(8, 8))\n","\n","plt.subplot(121)\n","plt.title('Is a real zebra?')\n","plt.imshow(discriminator_y(sample_zebra)[0, ..., -1], cmap='RdBu_r')\n","\n","plt.subplot(122)\n","plt.title('Is a real horse?')\n","plt.imshow(discriminator_x(sample_horse)[0, ..., -1], cmap='RdBu_r')\n","\n","plt.show()"],"metadata":{"id":"UlCI_7a56spn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["LAMBDA = 10\n","\n","loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"],"metadata":{"id":"TrQeZccn6t34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def discriminator_loss(real, generated):\n","  real_loss = loss_obj(tf.ones_like(real), real)\n","\n","  generated_loss = loss_obj(tf.zeros_like(generated), generated)\n","\n","  total_disc_loss = real_loss + generated_loss\n","\n","  return total_disc_loss * 0.5\n","\n","def generator_loss(generated):\n","  return loss_obj(tf.ones_like(generated), generated)"],"metadata":{"id":"-Iz_UDlH60Ox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calc_cycle_loss(real_image, cycled_image):\n","  loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n","\n","  return LAMBDA * loss1\n","\n","def identity_loss(real_image, same_image):\n","  loss = tf.reduce_mean(tf.abs(real_image - same_image))\n","  return LAMBDA * 0.5 * loss\n"],"metadata":{"id":"-bWI9Vnp62RM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","\n","discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n","discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"],"metadata":{"id":"IIzamNXs65Qq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["checkpoint_path = \"./checkpoints/train\"\n","\n","ckpt = tf.train.Checkpoint(generator_g=generator_g,\n","                           generator_f=generator_f,\n","                           discriminator_x=discriminator_x,\n","                           discriminator_y=discriminator_y,\n","                           generator_g_optimizer=generator_g_optimizer,\n","                           generator_f_optimizer=generator_f_optimizer,\n","                           discriminator_x_optimizer=discriminator_x_optimizer,\n","                           discriminator_y_optimizer=discriminator_y_optimizer)\n","\n","ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n","\n","# if a checkpoint exists, restore the latest checkpoint.\n","if ckpt_manager.latest_checkpoint:\n","  ckpt.restore(ckpt_manager.latest_checkpoint)\n","  print ('Latest checkpoint restored!!')"],"metadata":{"id":"x7KGLY2j66Sw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 10\n","\n","def generate_images(model, test_input):\n","  prediction = model(test_input)\n","\n","  plt.figure(figsize=(12, 12))\n","\n","  display_list = [test_input[0], prediction[0]]\n","  title = ['Input Image', 'Predicted Image']\n","\n","  for i in range(2):\n","    plt.subplot(1, 2, i+1)\n","    plt.title(title[i])\n","    # getting the pixel values between [0, 1] to plot it.\n","    plt.imshow(display_list[i] * 0.5 + 0.5)\n","    plt.axis('off')\n","  plt.show()"],"metadata":{"id":"d9fOw-8r67Xh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tf.function\n","def train_step(real_x, real_y):\n","  # persistent is set to True because the tape is used more than\n","  # once to calculate the gradients.\n","  with tf.GradientTape(persistent=True) as tape:\n","    # Generator G translates X -> Y\n","    # Generator F translates Y -> X.\n","\n","    fake_y = generator_g(real_x, training=True)\n","    cycled_x = generator_f(fake_y, training=True)\n","\n","    fake_x = generator_f(real_y, training=True)\n","    cycled_y = generator_g(fake_x, training=True)\n","\n","    # same_x and same_y are used for identity loss.\n","    same_x = generator_f(real_x, training=True)\n","    same_y = generator_g(real_y, training=True)\n","\n","    disc_real_x = discriminator_x(real_x, training=True)\n","    disc_real_y = discriminator_y(real_y, training=True)\n","\n","    disc_fake_x = discriminator_x(fake_x, training=True)\n","    disc_fake_y = discriminator_y(fake_y, training=True)\n","\n","    # calculate the loss\n","    gen_g_loss = generator_loss(disc_fake_y)\n","    gen_f_loss = generator_loss(disc_fake_x)\n","\n","    total_cycle_loss = calc_cycle_loss(real_x, cycled_x) + calc_cycle_loss(real_y, cycled_y)\n","\n","    # Total generator loss = adversarial loss + cycle loss\n","    total_gen_g_loss = gen_g_loss + total_cycle_loss + identity_loss(real_y, same_y)\n","    total_gen_f_loss = gen_f_loss + total_cycle_loss + identity_loss(real_x, same_x)\n","\n","    disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n","    disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n","\n","  # Calculate the gradients for generator and discriminator\n","  generator_g_gradients = tape.gradient(total_gen_g_loss,\n","                                        generator_g.trainable_variables)\n","  generator_f_gradients = tape.gradient(total_gen_f_loss,\n","                                        generator_f.trainable_variables)\n","\n","  discriminator_x_gradients = tape.gradient(disc_x_loss,\n","                                            discriminator_x.trainable_variables)\n","  discriminator_y_gradients = tape.gradient(disc_y_loss,\n","                                            discriminator_y.trainable_variables)\n","\n","  # Apply the gradients to the optimizer\n","  generator_g_optimizer.apply_gradients(zip(generator_g_gradients,\n","                                            generator_g.trainable_variables))\n","\n","  generator_f_optimizer.apply_gradients(zip(generator_f_gradients,\n","                                            generator_f.trainable_variables))\n","\n","  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients,\n","                                                discriminator_x.trainable_variables))\n","\n","  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients,\n","                                                discriminator_y.trainable_variables))"],"metadata":{"id":"pyi-y1PA69x8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  n = 0\n","  for image_x, image_y in tf.data.Dataset.zip((train_horses, train_zebras)):\n","    train_step(image_x, image_y)\n","    if n % 10 == 0:\n","      print ('.', end='')\n","    n += 1\n","\n","  clear_output(wait=True)\n","  # Using a consistent image (sample_horse) so that the progress of the model\n","  # is clearly visible.\n","  generate_images(generator_g, sample_horse)\n","\n","  if (epoch + 1) % 5 == 0:\n","    ckpt_save_path = ckpt_manager.save()\n","    print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n","                                                         ckpt_save_path))\n","\n","  print ('Time taken for epoch {} is {} sec\\n'.format(epoch + 1,\n","                                                      time.time()-start))"],"metadata":{"id":"YA5IcQ4H6-7G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run the trained model on the test dataset\n","for inp in test_horses.take(5):\n","  generate_images(generator_g, inp)"],"metadata":{"id":"RYYpd3gP7ADJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"WjDFHmuL7BQJ"},"execution_count":null,"outputs":[]}]}