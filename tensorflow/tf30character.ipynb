{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPLBBi5HloTdaS6Qd83HhkK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 글자 수준의 LSTM 텍스트 생성 모델 구현\n","\n","https://ml-ko.kr/dl-with-python/8.1-text-generation-with-lstm.html 참고"],"metadata":{"id":"TwrSrssgmszK"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"fheYX01ng7Ie"},"outputs":[],"source":["from tensorflow import keras\n","import numpy as np\n","\n","# path = keras.utils.get_file(\n","#     'nietzsche.txt',\n","#     origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n","# text = open(path).read().lower()\n","\n","path = keras.utils.get_file(\n","    'rnn_short_toji.txt',\n","    origin='https://raw.githubusercontent.com/pykwon/etc/master/rnn_short_toji.txt')\n","text = open(path).read().lower()\n","\n","print('말뭉치 크기:', len(text))"]},{"cell_type":"code","source":["# 60개 글자로 된 시퀀스를 추출합니다.\n","maxlen = 60\n","\n","# 세 글자씩 건너 뛰면서 새로운 시퀀스를 샘플링합니다.\n","step = 3\n","\n","# 추출한 시퀀스를 담을 리스트\n","sentences = []\n","\n","# 타깃(시퀀스 다음 글자)을 담을 리스트\n","next_chars = []\n","\n","for i in range(0, len(text) - maxlen, step):\n","    sentences.append(text[i: i + maxlen])\n","    next_chars.append(text[i + maxlen])\n","print('시퀀스 개수:', len(sentences))\n","\n","# 말뭉치에서 고유한 글자를 담은 리스트\n","chars = sorted(list(set(text)))\n","print('고유한 글자:', len(chars))\n","# chars 리스트에 있는 글자와 글자의 인덱스를 매핑한 딕셔너리\n","char_indices = dict((char, chars.index(char)) for char in chars)\n","\n","# 글자를 원-핫 인코딩하여 0과 1의 이진 배열로 바꿉니다.\n","print('벡터화...')\n","x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n","y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n","for i, sentence in enumerate(sentences):\n","    for t, char in enumerate(sentence):\n","        x[i, t, char_indices[char]] = 1\n","    y[i, char_indices[next_chars[i]]] = 1\n"],"metadata":{"id":"gU5EsJwMmv3G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","model = keras.models.Sequential() #글자 단위이이기에 embedding이 빠졌다.\n","model.add(layers.LSTM(128, input_shape=(maxlen, len(chars)),activation='tanh'))\n","model.add(layers.Dense(len(chars), activation='softmax'))\n","\n","optimizer = keras.optimizers.RMSprop(lr=0.01)\n","model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n","\n","print(model.summary())"],"metadata":{"id":"e8KB7FFlnZ4i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sample(preds, temperature=1.0): # temperature로 확률분포의 가중치를 조정하고 있음\n","    preds = np.asarray(preds).astype('float64')\n","    preds = np.log(preds) / temperature\n","    exp_preds = np.exp(preds)\n","    preds = exp_preds / np.sum(exp_preds)\n","    probas = np.random.multinomial(1, preds, 1)\n","    return np.argmax(probas)\n","\n","# variety등 다양한 값을 넣어보는 것 - 결과가 조금씩 나오게 됨"],"metadata":{"id":"U1fbQlykofRW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import sys\n","\n","random.seed(42)\n","start_index = random.randint(0, len(text) - maxlen - 1)\n","\n","# 60 에포크 동안 모델을 훈련합니다\n","for epoch in range(1, 60):\n","    print('에포크', epoch)\n","    # 데이터에서 한 번만 반복해서 모델을 학습합니다\n","    model.fit(x, y, batch_size=128, epochs=1)\n","\n","    # 무작위로 시드 텍스트를 선택합니다\n","    seed_text = text[start_index: start_index + maxlen]\n","    print('--- 시드 텍스트: \"' + seed_text + '\"')\n","\n","    # 여러가지 샘플링 온도를 시도합니다\n","    for temperature in [0.2, 0.5, 1.0, 1.2]:\n","        print('------ 온도:', temperature)\n","        generated_text = seed_text\n","        sys.stdout.write(generated_text)\n","\n","        # 시드 텍스트에서 시작해서 400개의 글자를 생성합니다\n","        for i in range(400):\n","            # 지금까지 생성된 글자를 원-핫 인코딩으로 바꿉니다\n","            sampled = np.zeros((1, maxlen, len(chars)))\n","            for t, char in enumerate(generated_text):\n","                sampled[0, t, char_indices[char]] = 1.\n","\n","            # 다음 글자를 샘플링합니다 - 글자단위로\n","            preds = model.predict(sampled, verbose=0)[0]\n","            next_index = sample(preds, temperature)\n","            next_char = chars[next_index]\n","\n","            generated_text += next_char\n","            generated_text = generated_text[1:]\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()\n","\n","        #학습량이 늘어나며 우리가 더 알아보기 쉬운 글들로 바뀐다.\n"],"metadata":{"id":"NmX2Cq5Qo7W3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","import sys\n","\n","random.seed(42)\n","start_index = random.randint(0, len(text) - maxlen - 1)\n","\n","# 60 에포크 동안 모델을 훈련합니다\n","for epoch in range(1, 60):\n","    print('에포크', epoch)\n","    # 데이터에서 한 번만 반복해서 모델을 학습합니다\n","    model.fit(x, y, batch_size=128, epochs=1)\n","\n","    # 무작위로 시드 텍스트를 선택합니다\n","    seed_text = text[start_index: start_index + maxlen]\n","    print('--- 시드 텍스트: \"' + seed_text + '\"')\n","\n","    # 여러가지 샘플링 온도를 시도합니다\n","    for temperature in [0.2, 0.5, 1.0, 1.2]:\n","        print('------ 온도:', temperature)\n","        generated_text = seed_text\n","        sys.stdout.write(generated_text)\n","\n","        # 시드 텍스트에서 시작해서 400개의 글자를 생성합니다\n","        for i in range(400):\n","            # 지금까지 생성된 글자를 원-핫 인코딩으로 바꿉니다\n","            sampled = np.zeros((1, maxlen, len(chars)))\n","            for t, char in enumerate(generated_text):\n","                sampled[0, t, char_indices[char]] = 1.\n","\n","            # 다음 글자를 샘플링합니다\n","            preds = model.predict(sampled, verbose=0)[0]\n","            next_index = sample(preds, temperature)\n","            next_char = chars[next_index]\n","\n","            generated_text += next_char\n","            generated_text = generated_text[1:]\n","\n","            sys.stdout.write(next_char)\n","            sys.stdout.flush()\n","        print()"],"metadata":{"id":"lmccC7TBxQWt"},"execution_count":null,"outputs":[]}]}