{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNBH5TqZn/nPpExGXbImU33"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":[],"metadata":{"id":"ttoqMz5Xu7Ko"}},{"cell_type":"markdown","source":["# FACE image generation with StyleGAN\n","\n","https://keras.io/examples/generative/stylegan/"],"metadata":{"id":"bt-CFiP8u8GC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hO0OFlmru4Cp"},"outputs":[],"source":["!pip install tensorflow_addons"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from functools import partial\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","from tensorflow_addons.layers import InstanceNormalization\n","\n","import gdown\n","from zipfile import ZipFile"],"metadata":{"id":"Ev5m75njvQh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def log2(x):\n","    return int(np.log2(x))\n","\n","\n","# we use different batch size for different resolution, so larger image size\n","# could fit into GPU memory. The keys is image resolution in log2\n","batch_sizes = {2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 8, 8: 4, 9: 2, 10: 1}\n","# We adjust the train step accordingly\n","train_step_ratio = {k: batch_sizes[2] / v for k, v in batch_sizes.items()}\n","\n","\n","os.makedirs(\"celeba_gan\")\n","\n","url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n","output = \"celeba_gan/data.zip\"\n","gdown.download(url, output, quiet=True)\n","\n","with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n","    zipobj.extractall(\"celeba_gan\")\n","\n","# Create a dataset from our folder, and rescale the images to the [0-1] range:\n","\n","ds_train = keras.utils.image_dataset_from_directory(\n","    \"celeba_gan\", label_mode=None, image_size=(64, 64), batch_size=32\n",")\n","\n","\n","def resize_image(res, image):\n","    # only downsampling, so use nearest neighbor that is faster to run\n","    image = tf.image.resize(\n","        image, (res, res), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n","    )\n","    image = tf.cast(image, tf.float32) / 127.5 - 1.0\n","    return image\n","\n","\n","def create_dataloader(res):\n","    batch_size = batch_sizes[log2(res)]\n","    # NOTE: we unbatch the dataset so we can `batch()` it again with the `drop_remainder=True` option\n","    # since the model only supports a single batch size\n","    dl = ds_train.map(partial(resize_image, res), num_parallel_calls=tf.data.AUTOTUNE).unbatch()\n","    dl = dl.shuffle(200).batch(batch_size, drop_remainder=True).prefetch(1).repeat()\n","    return dl\n"],"metadata":{"id":"Kj_CVGDEwruA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def plot_images(images, log2_res, fname=\"\"):\n","    scales = {2: 0.5, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8}\n","    scale = scales[log2_res]\n","\n","    grid_col = min(images.shape[0], int(32 // scale))\n","    grid_row = 1\n","\n","    f, axarr = plt.subplots(\n","        grid_row, grid_col, figsize=(grid_col * scale, grid_row * scale)\n","    )\n","\n","    for row in range(grid_row):\n","        ax = axarr if grid_row == 1 else axarr[row]\n","        for col in range(grid_col):\n","            ax[col].imshow(images[row * grid_col + col])\n","            ax[col].axis(\"off\")\n","    plt.show()\n","    if fname:\n","        f.savefig(fname)"],"metadata":{"id":"mfTD4p41wwG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def fade_in(alpha, a, b):\n","    return alpha * a + (1.0 - alpha) * b\n","\n","\n","def wasserstein_loss(y_true, y_pred):\n","    return -tf.reduce_mean(y_true * y_pred)\n","\n","\n","def pixel_norm(x, epsilon=1e-8):\n","    return x / tf.math.sqrt(tf.reduce_mean(x ** 2, axis=-1, keepdims=True) + epsilon)\n","\n","\n","def minibatch_std(input_tensor, epsilon=1e-8):\n","    n, h, w, c = tf.shape(input_tensor)\n","    group_size = tf.minimum(4, n)\n","    x = tf.reshape(input_tensor, [group_size, -1, h, w, c])\n","    group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False)\n","    group_std = tf.sqrt(group_var + epsilon)\n","    avg_std = tf.reduce_mean(group_std, axis=[1, 2, 3], keepdims=True)\n","    x = tf.tile(avg_std, [group_size, h, w, 1])\n","    return tf.concat([input_tensor, x], axis=-1)\n","\n","\n","class EqualizedConv(layers.Layer):\n","    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n","        super().__init__(**kwargs)\n","        self.kernel = kernel\n","        self.out_channels = out_channels\n","        self.gain = gain\n","        self.pad = kernel != 1\n","\n","    def build(self, input_shape):\n","        self.in_channels = input_shape[-1]\n","        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n","        self.w = self.add_weight(\n","            shape=[self.kernel, self.kernel, self.in_channels, self.out_channels],\n","            initializer=initializer,\n","            trainable=True,\n","            name=\"kernel\",\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.out_channels,), initializer=\"zeros\", trainable=True, name=\"bias\"\n","        )\n","        fan_in = self.kernel * self.kernel * self.in_channels\n","        self.scale = tf.sqrt(self.gain / fan_in)\n","\n","    def call(self, inputs):\n","        if self.pad:\n","            x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"REFLECT\")\n","        else:\n","            x = inputs\n","        output = (\n","            tf.nn.conv2d(x, self.scale * self.w, strides=1, padding=\"VALID\") + self.b\n","        )\n","        return output\n","\n","\n","class EqualizedDense(layers.Layer):\n","    def __init__(self, units, gain=2, learning_rate_multiplier=1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.units = units\n","        self.gain = gain\n","        self.learning_rate_multiplier = learning_rate_multiplier\n","\n","    def build(self, input_shape):\n","        self.in_channels = input_shape[-1]\n","        initializer = keras.initializers.RandomNormal(\n","            mean=0.0, stddev=1.0 / self.learning_rate_multiplier\n","        )\n","        self.w = self.add_weight(\n","            shape=[self.in_channels, self.units],\n","            initializer=initializer,\n","            trainable=True,\n","            name=\"kernel\",\n","        )\n","        self.b = self.add_weight(\n","            shape=(self.units,), initializer=\"zeros\", trainable=True, name=\"bias\"\n","        )\n","        fan_in = self.in_channels\n","        self.scale = tf.sqrt(self.gain / fan_in)\n","\n","    def call(self, inputs):\n","        output = tf.add(tf.matmul(inputs, self.scale * self.w), self.b)\n","        return output * self.learning_rate_multiplier\n","\n","\n","class AddNoise(layers.Layer):\n","    def build(self, input_shape):\n","        n, h, w, c = input_shape[0]\n","        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n","        self.b = self.add_weight(\n","            shape=[1, 1, 1, c], initializer=initializer, trainable=True, name=\"kernel\"\n","        )\n","\n","    def call(self, inputs):\n","        x, noise = inputs\n","        output = x + self.b * noise\n","        return output\n","\n","\n","class AdaIN(layers.Layer):\n","    def __init__(self, gain=1, **kwargs):\n","        super().__init__(**kwargs)\n","        self.gain = gain\n","\n","    def build(self, input_shapes):\n","        x_shape = input_shapes[0]\n","        w_shape = input_shapes[1]\n","\n","        self.w_channels = w_shape[-1]\n","        self.x_channels = x_shape[-1]\n","\n","        self.dense_1 = EqualizedDense(self.x_channels, gain=1)\n","        self.dense_2 = EqualizedDense(self.x_channels, gain=1)\n","\n","    def call(self, inputs):\n","        x, w = inputs\n","        ys = tf.reshape(self.dense_1(w), (-1, 1, 1, self.x_channels))\n","        yb = tf.reshape(self.dense_2(w), (-1, 1, 1, self.x_channels))\n","        return ys * x + yb"],"metadata":{"id":"fAvqRaI3wwxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Mapping(num_stages, input_shape=512):\n","    z = layers.Input(shape=(input_shape))\n","    w = pixel_norm(z)\n","    for i in range(8):\n","        w = EqualizedDense(512, learning_rate_multiplier=0.01)(w)\n","        w = layers.LeakyReLU(0.2)(w)\n","    w = tf.tile(tf.expand_dims(w, 1), (1, num_stages, 1))\n","    return keras.Model(z, w, name=\"mapping\")\n","\n","\n","class Generator:\n","    def __init__(self, start_res_log2, target_res_log2):\n","        self.start_res_log2 = start_res_log2\n","        self.target_res_log2 = target_res_log2\n","        self.num_stages = target_res_log2 - start_res_log2 + 1\n","        # list of generator blocks at increasing resolution\n","        self.g_blocks = []\n","        # list of layers to convert g_block activation to RGB\n","        self.to_rgb = []\n","        # list of noise input of different resolutions into g_blocks\n","        self.noise_inputs = []\n","        # filter size to use at each stage, keys are log2(resolution)\n","        self.filter_nums = {\n","            0: 512,\n","            1: 512,\n","            2: 512,  # 4x4\n","            3: 512,  # 8x8\n","            4: 512,  # 16x16\n","            5: 512,  # 32x32\n","            6: 256,  # 64x64\n","            7: 128,  # 128x128\n","            8: 64,  # 256x256\n","            9: 32,  # 512x512\n","            10: 16,\n","        }  # 1024x1024\n","\n","        start_res = 2 ** start_res_log2\n","        self.input_shape = (start_res, start_res, self.filter_nums[start_res_log2])\n","        self.g_input = layers.Input(self.input_shape, name=\"generator_input\")\n","\n","        for i in range(start_res_log2, target_res_log2 + 1):\n","            filter_num = self.filter_nums[i]\n","            res = 2 ** i\n","            self.noise_inputs.append(\n","                layers.Input(shape=(res, res, 1), name=f\"noise_{res}x{res}\")\n","            )\n","            to_rgb = Sequential(\n","                [\n","                    layers.InputLayer(input_shape=(res, res, filter_num)),\n","                    EqualizedConv(3, 1, gain=1),\n","                ],\n","                name=f\"to_rgb_{res}x{res}\",\n","            )\n","            self.to_rgb.append(to_rgb)\n","            is_base = i == self.start_res_log2\n","            if is_base:\n","                input_shape = (res, res, self.filter_nums[i - 1])\n","            else:\n","                input_shape = (2 ** (i - 1), 2 ** (i - 1), self.filter_nums[i - 1])\n","            g_block = self.build_block(\n","                filter_num, res=res, input_shape=input_shape, is_base=is_base\n","            )\n","            self.g_blocks.append(g_block)\n","\n","    def build_block(self, filter_num, res, input_shape, is_base):\n","        input_tensor = layers.Input(shape=input_shape, name=f\"g_{res}\")\n","        noise = layers.Input(shape=(res, res, 1), name=f\"noise_{res}\")\n","        w = layers.Input(shape=512)\n","        x = input_tensor\n","\n","        if not is_base:\n","            x = layers.UpSampling2D((2, 2))(x)\n","            x = EqualizedConv(filter_num, 3)(x)\n","\n","        x = AddNoise()([x, noise])\n","        x = layers.LeakyReLU(0.2)(x)\n","        x = InstanceNormalization()(x)\n","        x = AdaIN()([x, w])\n","\n","        x = EqualizedConv(filter_num, 3)(x)\n","        x = AddNoise()([x, noise])\n","        x = layers.LeakyReLU(0.2)(x)\n","        x = InstanceNormalization()(x)\n","        x = AdaIN()([x, w])\n","        return keras.Model([input_tensor, w, noise], x, name=f\"genblock_{res}x{res}\")\n","\n","    def grow(self, res_log2):\n","        res = 2 ** res_log2\n","\n","        num_stages = res_log2 - self.start_res_log2 + 1\n","        w = layers.Input(shape=(self.num_stages, 512), name=\"w\")\n","\n","        alpha = layers.Input(shape=(1), name=\"g_alpha\")\n","        x = self.g_blocks[0]([self.g_input, w[:, 0], self.noise_inputs[0]])\n","\n","        if num_stages == 1:\n","            rgb = self.to_rgb[0](x)\n","        else:\n","            for i in range(1, num_stages - 1):\n","\n","                x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n","\n","            old_rgb = self.to_rgb[num_stages - 2](x)\n","            old_rgb = layers.UpSampling2D((2, 2))(old_rgb)\n","\n","            i = num_stages - 1\n","            x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n","\n","            new_rgb = self.to_rgb[i](x)\n","\n","            rgb = fade_in(alpha[0], new_rgb, old_rgb)\n","\n","        return keras.Model(\n","            [self.g_input, w, self.noise_inputs, alpha],\n","            rgb,\n","            name=f\"generator_{res}_x_{res}\",\n","        )\n","\n","\n","class Discriminator:\n","    def __init__(self, start_res_log2, target_res_log2):\n","        self.start_res_log2 = start_res_log2\n","        self.target_res_log2 = target_res_log2\n","        self.num_stages = target_res_log2 - start_res_log2 + 1\n","        # filter size to use at each stage, keys are log2(resolution)\n","        self.filter_nums = {\n","            0: 512,\n","            1: 512,\n","            2: 512,  # 4x4\n","            3: 512,  # 8x8\n","            4: 512,  # 16x16\n","            5: 512,  # 32x32\n","            6: 256,  # 64x64\n","            7: 128,  # 128x128\n","            8: 64,  # 256x256\n","            9: 32,  # 512x512\n","            10: 16,\n","        }  # 1024x1024\n","        # list of discriminator blocks at increasing resolution\n","        self.d_blocks = []\n","        # list of layers to convert RGB into activation for d_blocks inputs\n","        self.from_rgb = []\n","\n","        for res_log2 in range(self.start_res_log2, self.target_res_log2 + 1):\n","            res = 2 ** res_log2\n","            filter_num = self.filter_nums[res_log2]\n","            from_rgb = Sequential(\n","                [\n","                    layers.InputLayer(\n","                        input_shape=(res, res, 3), name=f\"from_rgb_input_{res}\"\n","                    ),\n","                    EqualizedConv(filter_num, 1),\n","                    layers.LeakyReLU(0.2),\n","                ],\n","                name=f\"from_rgb_{res}\",\n","            )\n","\n","            self.from_rgb.append(from_rgb)\n","\n","            input_shape = (res, res, filter_num)\n","            if len(self.d_blocks) == 0:\n","                d_block = self.build_base(filter_num, res)\n","            else:\n","                d_block = self.build_block(\n","                    filter_num, self.filter_nums[res_log2 - 1], res\n","                )\n","\n","            self.d_blocks.append(d_block)\n","\n","    def build_base(self, filter_num, res):\n","        input_tensor = layers.Input(shape=(res, res, filter_num), name=f\"d_{res}\")\n","        x = minibatch_std(input_tensor)\n","        x = EqualizedConv(filter_num, 3)(x)\n","        x = layers.LeakyReLU(0.2)(x)\n","        x = layers.Flatten()(x)\n","        x = EqualizedDense(filter_num)(x)\n","        x = layers.LeakyReLU(0.2)(x)\n","        x = EqualizedDense(1)(x)\n","        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n","\n","    def build_block(self, filter_num_1, filter_num_2, res):\n","        input_tensor = layers.Input(shape=(res, res, filter_num_1), name=f\"d_{res}\")\n","        x = EqualizedConv(filter_num_1, 3)(input_tensor)\n","        x = layers.LeakyReLU(0.2)(x)\n","        x = EqualizedConv(filter_num_2)(x)\n","        x = layers.LeakyReLU(0.2)(x)\n","        x = layers.AveragePooling2D((2, 2))(x)\n","        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n","\n","    def grow(self, res_log2):\n","        res = 2 ** res_log2\n","        idx = res_log2 - self.start_res_log2\n","        alpha = layers.Input(shape=(1), name=\"d_alpha\")\n","        input_image = layers.Input(shape=(res, res, 3), name=\"input_image\")\n","        x = self.from_rgb[idx](input_image)\n","        x = self.d_blocks[idx](x)\n","        if idx > 0:\n","            idx -= 1\n","            downsized_image = layers.AveragePooling2D((2, 2))(input_image)\n","            y = self.from_rgb[idx](downsized_image)\n","            x = fade_in(alpha[0], x, y)\n","\n","            for i in range(idx, -1, -1):\n","                x = self.d_blocks[i](x)\n","        return keras.Model([input_image, alpha], x, name=f\"discriminator_{res}_x_{res}\")"],"metadata":{"id":"UWxkmKsZw4f8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StyleGAN(tf.keras.Model):\n","    def __init__(self, z_dim=512, target_res=64, start_res=4):\n","        super().__init__()\n","        self.z_dim = z_dim\n","\n","        self.target_res_log2 = log2(target_res)\n","        self.start_res_log2 = log2(start_res)\n","        self.current_res_log2 = self.target_res_log2\n","        self.num_stages = self.target_res_log2 - self.start_res_log2 + 1\n","\n","        self.alpha = tf.Variable(1.0, dtype=tf.float32, trainable=False, name=\"alpha\")\n","\n","        self.mapping = Mapping(num_stages=self.num_stages)\n","        self.d_builder = Discriminator(self.start_res_log2, self.target_res_log2)\n","        self.g_builder = Generator(self.start_res_log2, self.target_res_log2)\n","        self.g_input_shape = self.g_builder.input_shape\n","\n","        self.phase = None\n","        self.train_step_counter = tf.Variable(0, dtype=tf.int32, trainable=False)\n","\n","        self.loss_weights = {\"gradient_penalty\": 10, \"drift\": 0.001}\n","\n","    def grow_model(self, res):\n","        tf.keras.backend.clear_session()\n","        res_log2 = log2(res)\n","        self.generator = self.g_builder.grow(res_log2)\n","        self.discriminator = self.d_builder.grow(res_log2)\n","        self.current_res_log2 = res_log2\n","        print(f\"\\nModel resolution:{res}x{res}\")\n","\n","    def compile(\n","        self, steps_per_epoch, phase, res, d_optimizer, g_optimizer, *args, **kwargs\n","    ):\n","        self.loss_weights = kwargs.pop(\"loss_weights\", self.loss_weights)\n","        self.steps_per_epoch = steps_per_epoch\n","        if res != 2 ** self.current_res_log2:\n","            self.grow_model(res)\n","            self.d_optimizer = d_optimizer\n","            self.g_optimizer = g_optimizer\n","\n","        self.train_step_counter.assign(0)\n","        self.phase = phase\n","        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n","        super().compile(*args, **kwargs)\n","\n","    @property\n","    def metrics(self):\n","        return [self.d_loss_metric, self.g_loss_metric]\n","\n","    def generate_noise(self, batch_size):\n","        noise = [\n","            tf.random.normal((batch_size, 2 ** res, 2 ** res, 1))\n","            for res in range(self.start_res_log2, self.target_res_log2 + 1)\n","        ]\n","        return noise\n","\n","    def gradient_loss(self, grad):\n","        loss = tf.square(grad)\n","        loss = tf.reduce_sum(loss, axis=tf.range(1, tf.size(tf.shape(loss))))\n","        loss = tf.sqrt(loss)\n","        loss = tf.reduce_mean(tf.square(loss - 1))\n","        return loss\n","\n","    def train_step(self, real_images):\n","\n","        self.train_step_counter.assign_add(1)\n","\n","        if self.phase == \"TRANSITION\":\n","            self.alpha.assign(\n","                tf.cast(self.train_step_counter / self.steps_per_epoch, tf.float32)\n","            )\n","        elif self.phase == \"STABLE\":\n","            self.alpha.assign(1.0)\n","        else:\n","            raise NotImplementedError\n","        alpha = tf.expand_dims(self.alpha, 0)\n","        batch_size = tf.shape(real_images)[0]\n","        real_labels = tf.ones(batch_size)\n","        fake_labels = -tf.ones(batch_size)\n","\n","        z = tf.random.normal((batch_size, self.z_dim))\n","        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n","        noise = self.generate_noise(batch_size)\n","\n","        # generator\n","        with tf.GradientTape() as g_tape:\n","            w = self.mapping(z)\n","            fake_images = self.generator([const_input, w, noise, alpha])\n","            pred_fake = self.discriminator([fake_images, alpha])\n","            g_loss = wasserstein_loss(real_labels, pred_fake)\n","\n","            trainable_weights = (\n","                self.mapping.trainable_weights + self.generator.trainable_weights\n","            )\n","            gradients = g_tape.gradient(g_loss, trainable_weights)\n","            self.g_optimizer.apply_gradients(zip(gradients, trainable_weights))\n","\n","        # discriminator\n","        with tf.GradientTape() as gradient_tape, tf.GradientTape() as total_tape:\n","            # forward pass\n","            pred_fake = self.discriminator([fake_images, alpha])\n","            pred_real = self.discriminator([real_images, alpha])\n","\n","            epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n","            interpolates = epsilon * real_images + (1 - epsilon) * fake_images\n","            gradient_tape.watch(interpolates)\n","            pred_fake_grad = self.discriminator([interpolates, alpha])\n","\n","            # calculate losses\n","            loss_fake = wasserstein_loss(fake_labels, pred_fake)\n","            loss_real = wasserstein_loss(real_labels, pred_real)\n","            loss_fake_grad = wasserstein_loss(fake_labels, pred_fake_grad)\n","\n","            # gradient penalty\n","            gradients_fake = gradient_tape.gradient(loss_fake_grad, [interpolates])\n","            gradient_penalty = self.loss_weights[\n","                \"gradient_penalty\"\n","            ] * self.gradient_loss(gradients_fake)\n","\n","            # drift loss\n","            all_pred = tf.concat([pred_fake, pred_real], axis=0)\n","            drift_loss = self.loss_weights[\"drift\"] * tf.reduce_mean(all_pred ** 2)\n","\n","            d_loss = loss_fake + loss_real + gradient_penalty + drift_loss\n","\n","            gradients = total_tape.gradient(\n","                d_loss, self.discriminator.trainable_weights\n","            )\n","            self.d_optimizer.apply_gradients(\n","                zip(gradients, self.discriminator.trainable_weights)\n","            )\n","\n","        # Update metrics\n","        self.d_loss_metric.update_state(d_loss)\n","        self.g_loss_metric.update_state(g_loss)\n","        return {\n","            \"d_loss\": self.d_loss_metric.result(),\n","            \"g_loss\": self.g_loss_metric.result(),\n","        }\n","\n","    def call(self, inputs: dict()):\n","        style_code = inputs.get(\"style_code\", None)\n","        z = inputs.get(\"z\", None)\n","        noise = inputs.get(\"noise\", None)\n","        batch_size = inputs.get(\"batch_size\", 1)\n","        alpha = inputs.get(\"alpha\", 1.0)\n","        alpha = tf.expand_dims(alpha, 0)\n","        if style_code is None:\n","            if z is None:\n","                z = tf.random.normal((batch_size, self.z_dim))\n","            style_code = self.mapping(z)\n","\n","        if noise is None:\n","            noise = self.generate_noise(batch_size)\n","\n","        # self.alpha.assign(alpha)\n","\n","        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n","        images = self.generator([const_input, style_code, noise, alpha])\n","        images = np.clip((images * 0.5 + 0.5) * 255, 0, 255).astype(np.uint8)\n","\n","        return images"],"metadata":{"id":"RMn4_Llyw717"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["START_RES = 4\n","TARGET_RES = 128\n","\n","style_gan = StyleGAN(start_res=START_RES, target_res=TARGET_RES)"],"metadata":{"id":"TiSNxa-ow-nF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(\n","    start_res=START_RES,\n","    target_res=TARGET_RES,\n","    steps_per_epoch=5000,\n","    display_images=True,\n","):\n","    opt_cfg = {\"learning_rate\": 1e-3, \"beta_1\": 0.0, \"beta_2\": 0.99, \"epsilon\": 1e-8}\n","\n","    val_batch_size = 16\n","    val_z = tf.random.normal((val_batch_size, style_gan.z_dim))\n","    val_noise = style_gan.generate_noise(val_batch_size)\n","\n","    start_res_log2 = int(np.log2(start_res))\n","    target_res_log2 = int(np.log2(target_res))\n","\n","    for res_log2 in range(start_res_log2, target_res_log2 + 1):\n","        res = 2 ** res_log2\n","        for phase in [\"TRANSITION\", \"STABLE\"]:\n","            if res == start_res and phase == \"TRANSITION\":\n","                continue\n","\n","            train_dl = create_dataloader(res)\n","\n","            steps = int(train_step_ratio[res_log2] * steps_per_epoch)\n","\n","            style_gan.compile(\n","                d_optimizer=tf.keras.optimizers.legacy.Adam(**opt_cfg),\n","                g_optimizer=tf.keras.optimizers.legacy.Adam(**opt_cfg),\n","                loss_weights={\"gradient_penalty\": 10, \"drift\": 0.001},\n","                steps_per_epoch=steps,\n","                res=res,\n","                phase=phase,\n","                run_eagerly=False,\n","            )\n","\n","            prefix = f\"res_{res}x{res}_{style_gan.phase}\"\n","\n","            ckpt_cb = keras.callbacks.ModelCheckpoint(\n","                f\"checkpoints/stylegan_{res}x{res}.ckpt\",\n","                save_weights_only=True,\n","                verbose=0,\n","            )\n","            print(phase)\n","            style_gan.fit(\n","                train_dl, epochs=1, steps_per_epoch=steps, callbacks=[ckpt_cb]\n","            )\n","\n","            if display_images:\n","                images = style_gan({\"z\": val_z, \"noise\": val_noise, \"alpha\": 1.0})\n","                plot_images(images, res_log2)"],"metadata":{"id":"46AfCPl7xBzH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train(start_res=4, target_res=16, steps_per_epoch=1, display_images=False)"],"metadata":{"id":"XlfzobQaxD5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["url = \"https://github.com/soon-yau/stylegan_keras/releases/download/keras_example_v1.0/stylegan_128x128.ckpt.zip\"\n","\n","weights_path = keras.utils.get_file(\n","    \"stylegan_128x128.ckpt.zip\",\n","    url,\n","    extract=True,\n","    cache_dir=os.path.abspath(\".\"),\n","    cache_subdir=\"pretrained\",\n",")\n","\n","style_gan.grow_model(128)\n","style_gan.load_weights(os.path.join(\"pretrained/stylegan_128x128.ckpt\"))\n","\n","tf.random.set_seed(196)\n","batch_size = 2\n","z = tf.random.normal((batch_size, style_gan.z_dim))\n","w = style_gan.mapping(z)\n","noise = style_gan.generate_noise(batch_size=batch_size)\n","images = style_gan({\"style_code\": w, \"noise\": noise, \"alpha\": 1.0})\n","plot_images(images, 5)"],"metadata":{"id":"rQLrTupQxFq_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["alpha = 0.4\n","w_mix = np.expand_dims(alpha * w[0] + (1 - alpha) * w[1], 0)\n","noise_a = [np.expand_dims(n[0], 0) for n in noise]\n","mix_images = style_gan({\"style_code\": w_mix, \"noise\": noise_a})\n","image_row = np.hstack([images[0], images[1], mix_images[0]])\n","plt.figure(figsize=(9, 3))\n","plt.imshow(image_row)\n","plt.axis(\"off\")"],"metadata":{"id":"UjgPZ1VFxH5C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cqPMDzQkxKIo"},"execution_count":null,"outputs":[]}]}