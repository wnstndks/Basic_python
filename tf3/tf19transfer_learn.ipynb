{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMzX+iEmDdIR5Dq0wmXLqMi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["이미지 분류기를 직접 작성할 수도 있으나 이미 전문적으로 작성된 모델을 불러, 일부 영역의 학습을 통해 작성자가 원하는 모델을 만들수 있다.\n","\n","전이학습을 하면 방대한 데이터, 우수한 성능의 시스템이 없어도 우수모델 사용이 가능\n","\n","방법 첫번째 : 특성 추출 기법 : 사전 훈련된 모델의 마지막 완전 연결층 부분만 새로 학습\n","\n","방법 두번째 : 미세조정기법\n","베이스 모델은 MobileNet v2"],"metadata":{"id":"DJDg6XJqT88M"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dNbpybsT18k"},"outputs":[],"source":["%pip install tensorflow-datasets"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","\n","(raw_train, raw_validation, raw_test), metadata = tfds.load('cats_vs_dogs', split= ['train[:80%]','train[80%:90%]','train[:90%]'],with_info=True, as_supervised=True)\n"],"metadata":{"id":"K61zbKOYVMrU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(raw_train)\n","print(raw_train.take(1))\n","print(raw_validation)\n","print(raw_test)\n","print(metadata)"],"metadata":{"id":"hm6UuYzHWvFv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["mobile v2가 개 고양이 분류하는 곳"],"metadata":{"id":"xMJZlE6VXrnl"}},{"cell_type":"code","source":["get_label_name= metadata.features['label'].int2str\n","\n","for image, label in raw_train.take(1):\n","    plt.figure()\n","    plt.imshow(image)\n","    print(label.numpy())\n","    print(get_label_name(label)) # dog은 1 cat은 0\n","    plt.title(label.numpy())\n","    plt.show()\n"],"metadata":{"id":"hfao5TU3XUNM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["현재 데이터는 용량이 매우 크기 때문에 ram에 모두 로딩이 불가. 데이터 파이프라인을 이용하면 이미지를 일부만 적당히 연속해서 읽어 처리\n","읽어서 처리하고 ram에서 내보내기. - 일련의 처리 과정을 할 수 있다. -> 이미지 포매팅을 해야함\n","\n","\n"],"metadata":{"id":"3BZxTPv3aaun"}},{"cell_type":"code","source":["import tensorflow as tf\n","#이미지 포맷팅, 셔플링 처리 : MobileNet v2가 원하기 때문\n","\n","IMG_SIZE = 160\n","\n","\n","def format_exam(image, laebl):\n","    image = tf.cast(image, tf.float32)\n","    image = (image / 127.5)-1 #이미지 ㅔ이터를 실수화 하고 -1~1사이로 크기를 맞춤\n","    image=tf.image.resize(image, (IMG_SIZE,IMG_SIZE))\n","    return image, label\n","\n","train = raw_train.map(format_exam)\n","validation = raw_validation.map(format_exam)\n","test=raw_test.map(format_exam)\n","\n","#이미지 배치\n","BATCH_SIZE = 32\n","SHUFFLE_BUFFER_SIZE=1000\n","\n","train_batches = train.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n","validation_batches = validation.batch(BATCH_SIZE)\n","test_batches = test.batch(BATCH_SIZE)\n","\n","for image_batch, label_batch in train_batches.take(1):\n","    pass\n","\n","print(image_batch.shape,'',label_batch.shape)\n"],"metadata":{"id":"MtON9K2TYjtb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# base model 작성 : MobileNet v2 - 대량ㅇ의 자료로 충분히 학습된 분류 모델\n","IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n","\n","base_model= tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n","# 입력층 -> CNN층(특징 추출) -> 완전연결층\n","# include_top = False를 하면 입력층 -> CNN층(특징 추출)  => 학습이 끝난 녀석을 가져온 것이기에 그냥 써먹어야 한다.\n","\n","feature_batch=base_model(image_batch) # (32,160,160,3) 형태의 이미지 특징 반환\n","print(feature_batch) # shape= (32,5,5,1280)\n"],"metadata":{"id":"abuEAxDty-AQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 계층 동결\n","base_model.trainable = False # MobileNetV2 는 학습이 끝났으므로 우리가 만들 모델에서는 학습 안함\n","# print(base_model.summary())\n","\n","# 모델링\n","# 2\n","global_average_layer = tf.keras.layers.GlobalAveragePooling2D() # AveragePooling2D보다 급격하게 feature의 수를 줄임 - 우리가 생각하는 것보다 훨씬 빠름\n","feature_batch_average=global_average_layer(feature_batch)\n","print(feature_batch_average.shape)\n","\n","#3 순전파를 하고 난 다음에 형태는 최종적으로 빠져나갈때 1로 나감\n","prediction_layer = tf.keras.layers.Dense(1)\n","prediction_batch = prediction_layer(feature_batch_average)\n","print(prediction_batch.shape) #(32, 1)\n","\n","#3개의 레이어를 넣으면 모델이 만들어짐\n","model = tf.keras.Sequential([\n","    base_model, #특징 추출 베이스 모델\n","    global_average_layer, # 풀링 레이어\n","    prediction_layer # 완전연결층\n","])\n","\n"],"metadata":{"id":"pTmJHcVD0oV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_learning_rate = 0.0001\n","model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n","              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])\n","\n","print(model.summary())\n","\n","#Trainable params: 1281 (5.00 KB) 순전파에는 영향을 준다\n","\n","#현재 모델 성능\n","validation_step= 20\n","loss0, accuracy0 = model.evaluate(validation_batches, steps=validation_step)\n","print(\"loss0 :\", loss0)\n","print(\"accuracy0 :\", accuracy0)\n","\n","initial_epochs=10\n","history= model.fit(train_batches, epochs= initial_epochs, validation_data= validation_batches)\n","\n"],"metadata":{"id":"r1TaKvcg1cmh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습시 제공된 정보로 시각화\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","plt.figure(figsize=(5,5))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='acc')\n","plt.plot(val_acc, label='val_acc')\n","plt.legend(loc='lower right')\n","\n","plt.subplot(2,1,2)\n","plt.plot(loss, label='loss')\n","plt.plot(val_loss, label='val_loss')\n","plt.legend(loc='upper right')\n","plt.show()"],"metadata":{"id":"OHtCMkNm53n0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 파인튜닝이란?\n"," 사전 학습 모델(pre-trained model)에 도메인 특화 데이터를 추가 학습시켜 맞춤형 모델로 업데이트 하는 것을 의미\n"," 전이 학습이 끝난, 모델에 대해 레이어 일부를 재조정\n"," 즉, 기존에 있는 모델의 가장 끝단에 있는 레이어의 일부도 학습에 참여시키는 것\n"," 베이스 모델의 끝단 레이어 일부도 학습에 처리\n"],"metadata":{"id":"JMMiGkvjBTfW"}},{"cell_type":"code","source":["base_model.trainable=True # base모델의 학습 동결을 해제\n","\n","print('베이스 모델 레이어 수 : ', len(base_model.layers)) #154\n","fine_tune_at =100\n","\n","for layer in base_model.layers[:fine_tune_at]:\n","    layer.trainable= False #베이스 모델의 앞단 100개는 학습동결시킴\n","\n","model.compile(\n","    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),  # from_logits를 False로 설정\n","    optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate / 10),\n","    metrics=['accuracy']\n",")\n","\n","# 모델 요약 출력\n","print(model.summary())\n"],"metadata":{"id":"E3ldRJaK_TF5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 파인 튜닝 학습\n","fine_tune_epochs = 5\n","total_epochs = initial_epochs + fine_tune_epochs\n","\n","history_fine= model.fit(train_batches, epochs=total_epochs,initial_epoch= history.epoch[-1],validation_data= validation_batches)\n","\n","#시각화\n","acc += history_fine.history['accuracy']\n","val_acc += history_fine.history['val_accuracy']\n","loss+= history_fine.history['loss']\n","val_loss+= history_fine.history['val_loss']\n","\n","plt.figure(figsize=(5,5))\n","plt.subplot(2, 1, 1)\n","plt.plot(acc, label='acc')\n","plt.plot(val_acc, label='val_acc')\n","plt.ylim([0.8,1])\n","plt.plot([initial_epochs-1,initial_epochs-1],plt.ylim(),label='start fine tuning')\n","plt.legend(loc='lower right')\n","\n","plt.subplot(2,1,2)\n","plt.plot(loss, label='loss')\n","plt.plot(val_loss, label='val_loss')\n","plt.legend(loc='upper right')\n","plt.xlabel('epochs')\n","plt.show()"],"metadata":{"id":"5P118wJ1D87I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sBeIIhRaFy5G"},"execution_count":null,"outputs":[]}]}