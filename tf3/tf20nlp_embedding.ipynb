{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyO1FQfGgMPOGHA+nxR6fL7e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Word Embedding\n","단어를 수치화해 벡터로 표현하는 방식 중 하나, 희소 표현과 밀집 표현 등이 있다.\n","비정형화된 데이터를 숫자로 바꾸어 컴퓨터가 이해하는 형태로 번역하는 작업.\n","이미지와 자연어를 자유롭게 구사할 수 있음"],"metadata":{"id":"dv3sUuxT6ZFq"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_8NEl21yHrJ"},"outputs":[],"source":["import numpy as np\n","\n","# 데이터 인코딩\n","print('레이블 인코딩')\n","datas=['python','lan','program','computer','say']\n","datas.sort()\n","print(datas)\n","\n","# for 사용\n","values=[]\n","for x in range(len(datas)):\n","    values.append(x)\n","\n","print(values, type(values))\n","print()\n","\n","print('one-hot encoding')\n","onehot=np.eye(len(values))\n","print(onehot)\n","print(type(onehot))\n","print()\n","\n","print('인코딩 지원 클래스')\n","from sklearn.preprocessing import LabelEncoder\n","datas=['python','lan','program','computer','say']\n","encoder= LabelEncoder().fit(datas)\n","values=encoder.transform(datas)\n","print(values)\n","print(type(values),np.sort(values))\n","print()\n","\n","#단어를 수치화시켜 표현 - word를 수치화 해서 벡터로 만듦 그리고 학습을 위한 모델 및 각종 클래스들을 이용해서 어떤 단어가 밀접한 관련이 있는지 확인할 수 있음\n","#LabelEncoder를 써서 사용\n","\n","print('onehotencoding 지원 클래스')\n","from sklearn.preprocessing import OneHotEncoder\n","labels= values.reshape(-1,1)\n","print(labels)\n","print(labels.shape)\n","print()\n","\n","onehot= OneHotEncoder().fit(labels)\n","onehotValues= onehot.transform(labels)\n","print(onehotValues.toarray())\n","\n","#keras의 to_categorical 또는 pandas의 dummies를 사용해도 됨"]},{"cell_type":"markdown","source":["#word2vec\n","\n","단어의 의미를 다차원 공간에 실수로 벡터화 하는 분산표현 기법\n","단어간 유사성을 표현\n","\n","word2vec를 표현하면 코사인유사도를 표현해서 단어 사이의 관계를 알수 있게 된다, 모델을 만들고 관련된 이야기를 하여 단어 분류도 가능\n","\n","CBOW - 주변단어들을 가지고 중심단어를 예측한 방법, 단어간 유사도를 이용\n","\n","SKip Gram - 중심단어를 이용해서 주변단어를 찾아내는 것"],"metadata":{"id":"hryscC6oB_QB"}},{"cell_type":"code","source":["from gensim.models import word2vec\n","\n","sentence=[['python','lan','program','computer','say']] # 중첩 리스트를 사용 콤마가 안보이면 array, 콤마가 보이면 list\n","model= word2vec.Word2Vec(sentence, vector_size=50, min_count=1,sg=0) # SVM 커널 트릭 - 일차원으로 안되면 차원을 계속 늘려가면서 그 안에 데이터들을 올려놓는 방식\n","                                                                     # CBOW 인지 SKip-gram인지 예측\n","print(model)\n","print()\n","\n","word_vectors=model.wv # 단어 벡터를 생성하는 것\n","print('word_vectors : ',word_vectors)\n","print(word_vectors.key_to_index)\n","#dict타입으로 각각의 단어에 대해서 숫자를 제공해 준 것 - 랜덤하게 숫자가 잡힌다.\n","print(word_vectors.key_to_index.keys())\n","print(word_vectors.key_to_index.values())\n","vocabs = word_vectors.key_to_index.keys()\n","word_vectors_list = [word_vectors[v] for v in vocabs]\n","print(word_vectors_list[0],'\\n',len(word_vectors_list[0]))\n","# 사이각 거리, 프로그램 2번째\n","\n","print(word_vectors.similarity(w1='python',w2='computer')) # 두 단어의 유사도를 cos값으로 표현, 코사인 유사도를 이용, 가까운지 먼지를 알려줌\n","print(word_vectors.similarity(w1='python',w2='say'))\n","print(word_vectors.most_similar(positive='python')) #파이썬과의 관계\n","\n","# 시각화\n","import matplotlib.pyplot as plt\n","def plotFunc(vocabs, x,y):\n","    plt.figure(figsize=(5,4))\n","    plt.scatter(x,y)\n","    for i, v in enumerate(vocabs):\n","        plt.annotate(v, xy=(x[i],y[i]))\n","\n","from sklearn.decomposition import PCA\n","pca=PCA(n_components=2)\n","xys= pca.fit_transform(word_vectors_list)\n","xs=xys[:,0]\n","ys=xys[:,1]\n","\n","plotFunc(vocabs, xs, ys)\n","plt.show()\n"],"metadata":{"id":"0Iz2g3TO795g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kvVCLtMkIegJ"},"execution_count":null,"outputs":[]}]}