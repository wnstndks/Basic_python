{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMr2/XztnLTAWPQSxm9Rs7T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"-XXc5bcxwFgj"},"outputs":[],"source":["# CNN을 이용하여 개, 고양이 이미지 분류(이항분류)\n","import tensorflow as tf\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from keras.preprocessing.image import ImageDataGenerator\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import keras"]},{"cell_type":"code","source":["data_url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n","pathto_zip = keras.utils.get_file('cats_and_dogs.zip', origin=data_url, extract=True)  # 내가 줄 파일이름\n","PATH = os.path.join(os.path.dirname(pathto_zip), 'cats_and_dogs_filtered')  # 원본파일 이름\n","print(PATH)\n","\n","batch_size = 128\n","epochs = 15\n","IMG_HEIGHT = 150\n","IMG_WIDTH = 150\n","\n","# 데이터 준비\n","train_dir = os.path.join(PATH, 'train')\n","validation_dir = os.path.join(PATH, 'validation')\n","\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","print(train_cats_dir)\n","\n","num_cats_dir = len(os.listdir(train_cats_dir))\n","num_dogs_dir = len(os.listdir(train_dogs_dir))\n","print(os.listdir(train_cats_dir))\n","num_cats_val = len(os.listdir(validation_cats_dir))\n","num_dogs_val = len(os.listdir(validation_dogs_dir))\n","\n","total_train = num_cats_dir + num_dogs_dir\n","total_val = num_cats_val + num_dogs_val\n","\n","print('total_train cat : ', num_cats_dir)  # 1000\n","print('total_train dog : ', num_dogs_dir)  # 1000\n","print('total_validation dog : ', num_cats_val)  # 500\n","print('total_validation dog : ', num_dogs_val)  # 500\n","print('total train : ', total_train)  # 2000\n","print('total validation : ', total_val)  # 1000"],"metadata":{"id":"AMbDokr1wPZK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터를 실수 타입의 텐서로 전처리\n","# 2개의 이미지에 대한 라벨링\n","train_image_gen = ImageDataGenerator(rescale = 1./255)\n","validation_image_gen = ImageDataGenerator(rescale = 1./255)\n","\n","train_data_gen = train_image_gen.flow_from_directory(directory=train_dir, batch_size=batch_size, shuffle=True,\n","                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), class_mode='binary')  # (128, 150, 150, 3)  128개씩 150바이150 채널3\n","val_data_gen = validation_image_gen.flow_from_directory(directory=validation_dir, batch_size=batch_size,\n","                                                     target_size=(IMG_HEIGHT, IMG_WIDTH), class_mode='binary')\n","# flow_from_directory는 배치를 부한정 만들어 내므로 break를 해주는 것이 바람직\n","for a, b, in train_data_gen:\n","  print(a.shape, ' ', b.shape)  # (128, 150, 150, 3)   (128,) 트레인데이터, 라벨링\n","  print(b[0], b[1])\n","  break\n","\n","for a, b, in val_data_gen:\n","  break\n","\n","# 데이터 확인\n","sample_training_images, _ = next(train_data_gen)\n","\n","def plotImage(img_arr):\n","  fig, axes = plt.subplots(1, 5, figsize=(20,20))\n","  axes = axes.flatten()\n","  for img, ax in zip(img_arr, axes):\n","    ax.axis('off')  # 축은 볼 필요 없음\n","    ax.imshow(img)\n","  plt.tight_layout()\n","  plt.show()\n","\n","plotImage(sample_training_images[:5])\n","# print(sample_training_images[:1])  ...[0.18823531 0.2901961  0.24705884]]]]"],"metadata":{"id":"dP_EIVV_wTj-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델\n","model = Sequential([\n","    Conv2D(filters=16, kernel_size=(3, 3), strides=(1,1), padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Dropout(rate=0.2),\n","    Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), padding='same', activation='relu'),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Dropout(rate=0.2),\n","    Conv2D(filters=64, kernel_size=(3, 3), strides=(1,1), padding='same', activation='relu'),\n","    MaxPooling2D(pool_size=(2,2)),\n","    Dropout(rate=0.2),\n","    Flatten(),\n","    Dense(units=128, activation='relu'),\n","    Dense(units=64, activation='relu'),\n","    Dense(units=1),\n","])\n","\n","model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])  # 수치적으로 안정적\n","print(model.summary())"],"metadata":{"id":"rPiGJ2rH5Smm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습\n","history = model.fit_generator(\n","    train_data_gen,\n","    steps_per_epoch = total_train//batch_size,\n","    epochs=epochs,\n","    validation_data = val_data_gen,\n","    validation_steps = total_val // batch_size\n",")\n","\n","model.save('cat_dog.keras')"],"metadata":{"id":"YCoCSi1_y9cG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습 결과 시각화\n","acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs_range = range(epochs)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1,2,1)\n","plt.plot(epochs_range, acc, label='accuracy')\n","plt.plot(epochs_range, val_acc, label='val_accuracy')\n","plt.legend(loc='best')\n","plt.subplot(1,2,2)\n","plt.plot(epochs_range, loss, label='loss')\n","plt.plot(epochs_range, val_loss, label='val_loss')\n","plt.legend(loc='best')\n","plt.show()"],"metadata":{"id":"ilNFwGmy-KBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#새로운 이미지를 분류\n","import numpy as np\n","from google.colab import files\n","import tensorflow as tf\n","\n","mymodel=tf.keras.models.load_model('cat_dog.keras')\n","uploaded=files.upload()\n","print(uploaded.keys())\n","\n","for fn in uploaded.keys():\n","    path='/content/'+ fn\n","    img = tf.keras.utils.load_img(path, target_size=(150,150))\n","    x=tf.keras.utils.img_to_array(img)\n","    print(x.shape)\n","\n","    x=np.expand_dims(x,axis=0)\n","    print(x.shape)\n","    images=np.vstack([x])\n","    classes=mymodel.predict(images,batch_size=10)\n","    print(classes)\n","    print(classes[0])\n","\n","    if classes[0] > 0:\n","        print(fn+'은 댕댕이야')\n","    else:\n","        print(fn+'은 양이')"],"metadata":{"id":"4doGe4AN_56I"},"execution_count":null,"outputs":[]}]}