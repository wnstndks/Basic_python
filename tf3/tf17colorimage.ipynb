{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOozTKz0Ygo76pbopaA7FLI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dL1wNNXUPq7Z"},"outputs":[],"source":["# CIFAR-10 dataset\n","# The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n","# The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n","\n","# 레이블 : airplane,automobile,bird,cat,deer,dog,frog,horse,ship,truck\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.layers import Input,Flatten,Dense\n","from keras.models import Sequential,Model\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","from keras.datasets import cifar10\n"]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","\n","print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)  # (50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n","\n","plt.figure(figsize=(10, 3))\n","\n","plt.subplot(1, 3, 1)\n","plt.imshow(x_train[0])\n","plt.title(f'Label: {y_train[0]}')\n","\n","plt.subplot(1, 3, 2)\n","plt.imshow(x_train[1])\n","plt.title(f'Label: {y_train[1]}')\n","\n","plt.subplot(1, 3, 3)\n","plt.imshow(x_train[2])\n","plt.title(f'Label: {y_train[2]}')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"cvvffXVKQDvG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Normalize pixel values to be between 0 and 1\n","x_train = x_train.astype('float32') / 255.0\n","x_test = x_test.astype('float32') / 255.0\n","\n","NUM_CLASSES = 10\n","# Convert labels to categorical format\n","y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n","y_test = to_categorical(y_test, num_classes=NUM_CLASSES)\n","\n","print(x_train[0, 12, 13, 1])  # Accessing pixel value of the first image: 0번 채널 12행 13열 1번 채널 (그린 채널)\n"],"metadata":{"id":"54wR0Pm0ksy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CNN 없이 모델 작성\n","\n","# Sequential API 사용\n","# model = Sequential([\n","#     Dense(units=256, activation='relu', input_shape=(32,32,3)),\n","#     Flatten(),\n","#     Dense(units=128, activation='relu'),\n","#     Dense(units=NUM_CLASSES, activation='softmax'),\n","# ])\n","# print(model.summary())\n","\n","# Functional API 사용\n","# input_layer = Input((32, 32, 3))\n","# net = Flatten()(input_layer)\n","# net = Dense(units=256, activation='relu')(net)\n","# output_layer = Dense(units=NUM_CLASSES, activation='softmax')(net)\n","# model = Model(input_layer, output_layer)\n","# print(model.summary())\n","\n","\n","# CNN 레이어 Dense위에 추가\n","from keras.layers import Conv2D, MaxPool2D, Activation, ReLU, LeakyReLU, BatchNormalization\n","# BatchNormalization : 활성화 함수의 값이나 출력값을 정규화함. 학습속도 개선, 가중치 초기값 선택 의존성이 적어짐 => 과적합 방지\n","input_layer = Input((32, 32, 3))\n","net = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(input_layer)\n","net = BatchNormalization()(net)\n","net = LeakyReLU()(net)\n","net = MaxPool2D(pool_size=(2,2))(net)  # dropout 말고 batchnormalization쓰는 법\n","\n","net = Conv2D(filters=64, kernel_size=3, strides=1, padding='same')(net)\n","net = BatchNormalization()(net)\n","net = LeakyReLU()(net)\n","net = MaxPool2D(pool_size=(2,2))(net)\n","\n","net = Flatten()(net)\n","\n","net = Dense(units=256, activation='relu')(net)\n","net = BatchNormalization()(net)\n","net = LeakyReLU()(net)\n","\n","net = Dense(units=128)(net)\n","net = BatchNormalization()(net)\n","net = LeakyReLU()(net)\n","\n","output_layer = Dense(units=NUM_CLASSES, activation='softmax')(net)\n","model = Model(input_layer, output_layer)\n","print(model.summary())"],"metadata":{"id":"V-hTF8Ypm7qx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 컴파일\n","opt = Adam(learning_rate=0.01)\n","model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 훈련\n","model.fit(x_train, y_train, batch_size=128, epochs=10, shuffle=True, verbose=2)\n","\n","# 모델 평가\n","test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0, batch_size=128)\n","print('테스트 정확도:', test_accuracy)  # 테스트 정확도 출력\n","print('테스트 손실:', test_loss)  # 테스트 손실 출력\n","\n","# 클래스 레이블 매핑\n","CLASSES = np.array(['비행기', '자동차', '새', '고양이', '사슴', '개', '개구리', '말', '배', '트럭'])"],"metadata":{"id":"-YvsuWrZnwDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#예측\n","pred= model.predict(x_test[:10])\n","pred_single=CLASSES[np.argmax(pred,axis=1)]\n","actual_single=CLASSES[np.argmax(y_test[:10],axis=1)]\n","print('예측값 : ', pred_single)\n","print('실제값 : ', actual_single)\n","print('분류 실패 수 : ', (pred_single!=actual_single).sum())"],"metadata":{"id":"X0N1iYCGrq-S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","#시각화\n","fig= plt.figure(figsize=(15,3))\n","fig.subplots_adjust(hspace=0.4, wspace=0.2)\n","\n","for i, idx in enumerate(range(len(x_test[:10]))):\n","    img= x_test[idx]\n","    ax= fig.add_subplot(1,len(x_test[:10]),i+1)\n","    ax.axis('off')\n","    ax.text(0.5,-0.3,'pred='+str(pred_single[idx]), fontdict={'fontsize':10,'color':'blue'}, ha='center', transform=ax.transAxes)\n","    ax.text(0.5,-0.7,'actu='+str(actual_single[idx]), fontdict={'fontsize':10}, ha='center', transform=ax.transAxes)\n","    ax.imshow(img)\n","plt.show()"],"metadata":{"id":"LZVxPQUm2-7r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"TANlj_Dw4gg-"},"execution_count":null,"outputs":[]}]}