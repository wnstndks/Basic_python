{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyO8lKsLJ7QpAK2E26x/1dhD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yY-G00ANEvjd"},"outputs":[],"source":["# Attention score로부터 Importance 구하기 *\n","# Attention score는 주어진 문장 길이의 제곱으로 구해진 Matrix 형태인데, 어떻게 단어별로 중요도를 구할 수 있을까? 라는 의문이 생깁니다. 각 단어의 중요도를 계산하기 위해 입력 시퀀스의 다른 모든 단어에서 각 단어에 대한 Attention Score를 합산할 수 있습니다. (보통, 이는 한 단어의 embeding을 거친 feature vector를 의미할 수 있습니다) 한 단어에 대한 Attention score의 합산 결과는 중요성을 나타내는 단일 점수로 여겨질 수 있습니다.\n","# 다음은 코드의 예입니다.\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","\n","\n","vocab_size = 20000  # Only consider the top 20k words\n","maxlen = 200  # Only consider the first 200 words of each movie review\n","\n","word_index = tf.keras.datasets.imdb.get_word_index() # get {word : index}\n","index_word = {v : k for k,v in word_index.items()} # get {index : word}\n","index_word[0] = '<PAD>'\n","index_word[1] = '<START>'\n","index_word[2] = '<UNK>'\n","\n","(x_train, y_train), (x_valid, y_valid) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n","x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\n","x_valid = tf.keras.preprocessing.sequence.pad_sequences(x_valid, maxlen=maxlen)\n","\n","# token된 데이터 영문으로 출력해보기\n","DataIndex = 5\n","\" \".join([index_word[idx] for idx in x_train[DataIndex]])\n","y_train[DataIndex]\n","\n","EmbeddingDim = 128\n","WordLen = 200\n","\n","inputs = tf.keras.layers.Input(shape=(WordLen,))\n","embedding_layer = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=EmbeddingDim)(inputs)  # input_dim을 vocab_size로 변경\n","attn_output, weight = tf.keras.layers.MultiHeadAttention(num_heads=5, key_dim=4, use_bias=True)(\n","    embedding_layer, embedding_layer, return_attention_scores=True)\n","# 나머지 코드...\n","\n","Model_withWeight = tf.keras.Model(inputs=inputs, outputs=[weight])\n","\n","attention_weights = Model_withWeight.predict(x_valid[:2])\n","print(attention_weights.shape)   # (2, 5, 200, 200)\n","\n","import numpy as np\n","importance_scores = np.sum(attention_weights, axis=3)\n","print(importance_scores)"]},{"cell_type":"code","source":[],"metadata":{"id":"7qfhKShjFEHb"},"execution_count":null,"outputs":[]}]}