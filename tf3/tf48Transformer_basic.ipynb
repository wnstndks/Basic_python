{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNk5SjF44OeV7YEtHFjzekS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# imdb dataset으로 감성 분류"],"metadata":{"id":"PcQP3gkOFdTG"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras import layers"],"metadata":{"id":"VdyA-EawKFGg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0uvdXdrzFUiA"},"outputs":[],"source":["# encoder block\n","def transformer_encoder(inputs, head_size,num_heads,ff_dim,dropout=0):\n","    # Attention\n","    x= layers.LayerNormalization(epsilon=1e-6)(inputs) # sequence에 따른 고정길이 정규화로 BatchNormalization에 비해 언어 모델에 유연?\n","    x=layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n","    res = x+inputs\n","\n","    # FeedFprward NeuralNet\n","    x=layers.LayerNormalization(epsilon=1e-6)(res)\n","    x=layers.Conv1D(filters=ff_dim,kernel_size=1,activation='relu')(x)\n","    x=layers.Dropout(dropout)(x)\n","    x=layers.Conv1D(filters=inputs.shape[-1],kernel_size=1)(x)\n","    return x+res\n","\n","def build_sentment_model(input_shape,head_size, num_heads, ff_dim, num_transformer_blocks,mlp_units,dropout=0,mlp_dropout=0):\n","    inputs=keras.Input(shape=input_shape)\n","    embedding_layer=layers.Embedding(input_dim=10000,output_dim=64,input_length=input_shape[0])(inputs)\n","    x=embedding_layer+tf.random.normal(shape=tf.shape(embedding_layer))\n","    # Transformer blocks\n","    for _ in range(num_transformer_blocks):\n","        x=transformer_encoder(x,head_size,num_heads,ff_dim,dropout)\n","\n","    x = layers.GlobalAveragePooling1D()(x) # 공간차원축소\n","\n","    # MLP\n","    for dim in mlp_units:\n","        x=layers.Dense(dim, activation='relu')(x)\n","        x=layers.Dropout(mlp_dropout)(x)\n","\n","    outputs=layers.Dense(1,activation='sigmoid')(x)\n","    return keras.Model(inputs=inputs,outputs=outputs)\n"]},{"cell_type":"code","source":["(x_train, y_train),(x_val,y_val)= keras.datasets.imdb.load_data(num_words=10000)\n","x_train= keras.preprocessing.sequence.pad_sequences(x_train,maxlen=100)\n","x_val=keras.preprocessing.sequence.pad_sequences(x_val,maxlen=100)\n","\n","# example usage\n","input_shape=(100,)\n","head_size=256\n","num_heads=4\n","ff_dim=4\n","num_transformer_blocks=4\n","mlp_units=[128]\n","dropout=0.25\n","mlp_dropout=0.25\n","\n","model=build_sentment_model(\n","    input_shape,head_size, num_heads, ff_dim, num_transformer_blocks,mlp_units,dropout,mlp_dropout\n","    )\n","\n","print(model.summary())"],"metadata":{"id":"hx49d4C5JObM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy',optimizer = keras.optimizers.Adam(learning_rate=1e-4),metrics=['acc'])\n","\n","history = model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=10,batch_size=32,verbose=2)\n","print(history.history)\n"],"metadata":{"id":"4sBjeP9PKH_M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sre_constants import MAX_REPEAT\n","text_sample=[\"I love movie\", \"This movie sucks, It's so boring.\"]\n","max_len=100\n","tok=keras.datasets.imdb.get_word_index()\n","text_sequence=[[tok[word] if word in tok else 0 for word in sample.split()] for sample in text_sample]\n","text_sequence= keras.preprocessing.sequence.pad_sequences(text_sequence,maxlen=max_len)\n","# print(text_sequence)\n","\n","pred = model.predict(text_sequence) # 이항분류가 나오면 logistic regresssion과 logic 변환을 떠올려야 한다., odds비와 logit 변환을 떠올려야 한다.\n","\n","b_pred = (pred > 0.5).astype(int)\n","\n","for i, samp in enumerate(text_sample):\n","    print(f\"sample : {samp}\")\n","    print(f\"predicted : {'Positive' if b_pred[i]==1 else 'Negative'}\")\n","    print(f\"confidence : {pred[i][0]:.3f}\\n\")\n"],"metadata":{"id":"4xvPmDu7vtYy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6uly2AqqztLc"},"execution_count":null,"outputs":[]}]}